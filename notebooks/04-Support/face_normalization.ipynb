{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_cQX8dWu4Dv"
   },
   "source": [
    "# Face Detection with MediaPipe Tasks\n",
    "\n",
    "This notebook shows you how to use the MediaPipe Tasks Python API to detect faces in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89BlskiiyGDC"
   },
   "source": [
    "## Visualization utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLHhoIkkWYLQ"
   },
   "source": [
    "To better demonstrate the Face Detector API, we have created a set of visualization tools that will be used in this colab. These will draw a bounding box around detected faces, as well as markers over certain detected points on the faces."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H4aPO-hvbw3r"
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    face_landmarks_list = detection_result.face_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected faces to visualize.\n",
    "    for idx in range(len(face_landmarks_list)):\n",
    "        face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "        # Draw the face landmarks.\n",
    "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        face_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "        ])\n",
    "\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "\n",
    "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
    "    # Extract the face blendshapes category names and scores.\n",
    "    face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
    "    face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
    "    # The blendshapes are ordered in decreasing score value.\n",
    "    face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
    "    ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Label each bar with values\n",
    "    for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
    "        plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
    "\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title(\"Face Blendshapes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83PEJNp9yPBU"
   },
   "source": [
    "## Download test image\n",
    "\n",
    "To demonstrate Face Detection, you can download a sample image using the following code. Credits: https://pixabay.com/photos/brother-sister-girl-family-boy-977170/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tzXuqyIBlXer"
   },
   "source": [
    "!curl https://i.imgur.com/Vu2Nqwb.jpeg -s -o image.jpg\n",
    "\n",
    "IMAGE_FILE = 'image.jpg'\n",
    "# IMAGE_FILE = 'IMG_7676.jpeg'\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(IMAGE_FILE)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAFQm3HHi5OG"
   },
   "source": [
    "Optionally, you can upload your own image from your computer. To do this, uncomment the following code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy4r2_ePylIa"
   },
   "source": [
    "## Running inference and visualizing the results\n",
    "\n",
    "The final step is to run face detection on your selected image. This involves creating your FaceDetector object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
    "\n",
    "You can check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/face_detector/python) to learn more about configuration options that this solution supports."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yl_Oiye4mUuo"
   },
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an FaceLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='../../data/mediapipe/face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    output_face_blendshapes=True,\n",
    "    output_facial_transformation_matrixes=True,\n",
    "    num_faces=2)\n",
    "\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(IMAGE_FILE)\n",
    "\n",
    "# STEP 4: Detect face landmarks from the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the detection result. In this case, visualize it.\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "plt.imshow(annotated_image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "annotated_image.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(detection_result.face_landmarks[0])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Sample data: Replace this with your actual face landmarks data.\n",
    "face_landmarks_3d = np.array([[landmark.x, landmark.y, landmark.z] for landmark in detection_result.face_landmarks[0]])\n",
    "\n",
    "# Create the 3D scatter plot.\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=face_landmarks_3d[:, 0],\n",
    "    y=face_landmarks_3d[:, 1],\n",
    "    z=face_landmarks_3d[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=face_landmarks_3d[:, 2],  # Color by Z axis value\n",
    "        colorscale='Viridis',  # Color scale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Update the layout for better visualization\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z'\n",
    "    ),\n",
    "    width=700,\n",
    "    height=700,\n",
    "    margin=dict(r=20, l=10, b=10, t=10)\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "pio.show(fig)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "image = cv2.imread(IMAGE_FILE)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "landmarks_3d = np.array([[landmark.x, landmark.y, landmark.z] for landmark in detection_result.face_landmarks[0]])\n",
    "landmarks_2d = landmarks_3d[:, :2]\n",
    "\n",
    "print(f'min: {landmarks_3d[:, 0].min()} max: {landmarks_3d[:, 0].max()}')\n",
    "print(f'min: {landmarks_3d[:, 1].min()} max: {landmarks_3d[:, 1].max()}')\n",
    "print(f'min: {landmarks_3d[:, 2].min()} max: {landmarks_3d[:, 2].max()}')\n",
    "\n",
    "k = 3\n",
    "\n",
    "height, width = 36, 36\n",
    "\n",
    "# Project 3D landmarks onto a cylinder\n",
    "# u = np.arctan(landmarks_3d[:, 2] / landmarks_3d[:, 0])\n",
    "u = landmarks_3d[:, 0]\n",
    "v = landmarks_3d[:, 1]\n",
    "\n",
    "print(f'u.min: {u.min()} u.max: {u.max()}')\n",
    "print(f'v.min: {v.min()} v.max: {v.max()}')\n",
    "\n",
    "# Normalize u and v coordinates to the output image size\n",
    "# u = (u - u.min()) / (u.max() - u.min()) * width\n",
    "# v = (v - v.min()) / (v.max() - v.min()) * height\n",
    "\n",
    "print(f'u.min: {u.min()} u.max: {u.max()}')\n",
    "print(f'v.min: {v.min()} v.max: {v.max()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.scatter(u, v, c=landmarks_3d[:, 2], cmap='viridis')\n",
    "# Make the coordinate system origin the top-left corner\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "triangulation = Delaunay(landmarks_2d)\n",
    "\n",
    "# Fill the triangles with the average color of the triangle vertices\n",
    "# normalized_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "normalized_image = np.zeros_like(image)\n",
    "\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]\n",
    "\n",
    "for triangle_indices in triangulation.simplices:\n",
    "    print(f'triangle_indices: {triangle_indices}')\n",
    "    # Get coordinates of the source triangle in the input image\n",
    "    source_triangle = landmarks_2d[triangle_indices].astype(np.float32)\n",
    "    print(f'source_triangle: {source_triangle}')\n",
    "    \n",
    "    source_triangle[:, 0] = source_triangle[:, 0] * width\n",
    "    source_triangle[:, 1] = source_triangle[:, 1] * height\n",
    "    \n",
    "    # Convert the source_triangle to integer\n",
    "    source_triangle = source_triangle.astype(np.int32)\n",
    "    \n",
    "    print(f'source_triangle: {source_triangle}')\n",
    "    \n",
    "    random_color = np.random.randint(0, 256, 3)\n",
    "    r, g, b = float(random_color[0]), float(random_color[1]), float(random_color[2])\n",
    "    print(f'random_color: {random_color}')\n",
    "    \n",
    "    # Draw the triangle on the normalized image\n",
    "    cv2.fillConvexPoly(normalized_image, source_triangle, color=(r, g, b))\n",
    "    \n",
    "    # break\n",
    "\n",
    "plt.imshow(normalized_image)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
