{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test if GPU or MPS are available",
   "id": "eeaa2b5654416b60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    # Use the MPS (Multi-Process Service) to run the model\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    # Use the GPU to run the model\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    # Use the CPU to run the model\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ],
   "id": "db2108e8244196d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Num GPUs Available:', len(tf.config.experimental.list_physical_devices('GPU')))"
   ],
   "id": "829695c5db81f133",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tf.config.list_physical_devices()",
   "id": "b8e8b0669a84a818",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "docker run -it --rm --gpus all tensorflow/tensorflow:latest-gpu \\\n",
    "   python -c \"import tensorflow as tf; print(tf.config.list_physical_devices())\"\n",
    "```"
   ],
   "id": "7d58686bb6e4d087"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
