{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Silhouette\n",
    "\n",
    "This notebook shows how to extract the silhouette of a person from a video by using detectron2."
   ],
   "id": "6c15c98097025cbb"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "subject = 'Proband16'\n",
    "scenario = '101_natural_lighting'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "frames, meta = dataset.get_video_rgb(subject, scenario, show_progress=True)",
   "id": "e99b931fc0e3b112",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show the first frame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(frames[0])\n",
    "plt.show()"
   ],
   "id": "f549be88a4e976f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "im = frames[0]",
   "id": "62e18f53430f2de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "cfg = get_cfg()\n",
    "# model = \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
    "model = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "config_path = model_zoo.get_config_file(model)\n",
    "\n",
    "cfg.merge_from_file(config_path)\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model"
   ],
   "id": "cf3ade2ff6074f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ],
   "id": "a9068e03690e3ed6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "outputs",
   "id": "11d5d20a08a6a5be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prediction_masks = outputs[\"instances\"].pred_masks\n",
    "prediction_classes = outputs[\"instances\"].pred_classes\n",
    "\n",
    "prediction_masks.shape, prediction_classes.shape"
   ],
   "id": "f296936c3088989e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "plt.show()"
   ],
   "id": "cc0c38bbee901b79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the mask of the person\n",
    "person_class = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(\"person\")\n",
    "person_mask = prediction_masks[prediction_classes == person_class][0].cpu().numpy()"
   ],
   "id": "b5b9c3c797f5a9d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Only show the person, the rest is black\n",
    "plt.imshow(im * person_mask[:, :, None])\n",
    "plt.show()"
   ],
   "id": "6a26240be791d9e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract the silhouette from the video",
   "id": "298fa043eed0f2a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Run prediction on all frames\n",
    "masks = []\n",
    "\n",
    "for frame in tqdm(frames):\n",
    "    outputs = predictor(frame)\n",
    "    prediction_masks = outputs[\"instances\"].pred_masks\n",
    "    prediction_classes = outputs[\"instances\"].pred_classes\n",
    "    person_mask = prediction_masks[prediction_classes == person_class][0].cpu().numpy()\n",
    "    masks.append(person_mask)"
   ],
   "id": "f9b013b4779e55d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a video with the silhouette\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('silhouette.avi', fourcc, meta.fps, (im.shape[1], im.shape[0]))\n",
    "\n",
    "for idx, mask in tqdm(enumerate(masks), total=len(masks)):\n",
    "    frame = np.uint8(frames[idx] * mask[:, :, None])\n",
    "    out.write(frame)\n",
    "\n",
    "out.release()"
   ],
   "id": "f8a07f4319745f29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
