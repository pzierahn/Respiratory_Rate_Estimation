{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiratory_extraction.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "\n",
    "subject = 'Proband16'\n",
    "scenario = '101_natural_lighting'\n",
    "\n",
    "subject_frames, params = dataset.read_video_gray(subject, scenario)"
   ],
   "id": "38877d9593e0b11c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    'OFP_maxCorners': 100,\n",
    "    'OFP_qualityLevel': 0.1,\n",
    "    'OFP_minDistance': 7,\n",
    "    'OFP_mask': None,\n",
    "    'OFP_QualityLevelRV': 0.05,\n",
    "    'OFP_winSize': (15, 15),\n",
    "    'OFP_maxLevel': 2,\n",
    "    'FSS_maxCorners': 100,\n",
    "    'FSS_qualityLevel': 0.1,\n",
    "    'FSS_minDistance': 7,\n",
    "    'FSS_mask': None,\n",
    "    'FSS_QualityLevelRV': 0.05,\n",
    "    'FSS_FPN': 5,\n",
    "    'Filter_order': 3,\n",
    "    'Filter_LowPass': 0.1,\n",
    "    'Filter_HighPass': 0.6,\n",
    "    'RR_Algorithm_PC_Height': None,\n",
    "    'RR_Algorithm_PC_Threshold': None,\n",
    "    'RR_Algorithm_PC_MaxRR': 45,\n",
    "    'RR_Algorithm_NFCP_qualityLevel': 0.6\n",
    "}"
   ],
   "id": "eb6298885b947e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import respiratory_extraction.utils as utils\n",
    "import respiratory_extraction.models.optical_flow as optical_flow\n",
    "\n",
    "\n",
    "def find_roi(frame: np.ndarray) -> tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Find the region of interest (ROI) based on the face detection\n",
    "    :param frame: The frame to find the ROI\n",
    "    :return: The region of interest (ROI) coordinates (x, y, w, h)\n",
    "    \"\"\"\n",
    "\n",
    "    faces = utils.detect_faces(frame)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        raise ValueError('No face detected in the first frame')\n",
    "    elif len(faces) > 1:\n",
    "        raise ValueError('Multiple faces detected in the first frame')\n",
    "\n",
    "    # First face position and size\n",
    "    x, y, w, h = faces[0]\n",
    "\n",
    "    scale_x = int(w * 0.2)\n",
    "\n",
    "    # Calculate the region of interest (ROI) based on the face\n",
    "    chest_x = x - scale_x\n",
    "    chest_y = int(y + h + h * 0.7)\n",
    "    chest_w = w + scale_x * 2\n",
    "    chest_h = int(h * 0.5)\n",
    "\n",
    "    return chest_x, chest_y, chest_w, chest_h"
   ],
   "id": "434449646062376d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class FeaturePointStrategy(Enum):\n",
    "    special = 'special'\n",
    "    default = 'default'\n",
    "    roi = 'roi'\n",
    "    roi_special = 'roi_special'\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "    def uses_roi(self) -> bool:\n",
    "        return self == FeaturePointStrategy.roi or self == FeaturePointStrategy.roi_special\n",
    "\n",
    "    def uses_special(self) -> bool:\n",
    "        return self == FeaturePointStrategy.special or self == FeaturePointStrategy.roi_special\n",
    "\n",
    "\n",
    "def get_feature_points(\n",
    "        frame: np.ndarray,\n",
    "        quality_level=float(0.3),\n",
    "        quality_level_rv=float(0.05),\n",
    "        strategy=FeaturePointStrategy.default,\n",
    ") -> np.ndarray:\n",
    "    roi_mask = None\n",
    "    if strategy.uses_roi():\n",
    "        roi = find_roi(frame)\n",
    "        roi_mask = utils.roi_to_mask(frame, roi)\n",
    "\n",
    "    if strategy.uses_special():\n",
    "        feature_points = optical_flow.special_feature_point_selection(\n",
    "            frame,\n",
    "            fpn=hyperparameters['FSS_FPN'],\n",
    "            mask=roi_mask,\n",
    "            quality_level=quality_level,\n",
    "            quality_level_rv=quality_level_rv,\n",
    "        )\n",
    "    else:\n",
    "        feature_points = optical_flow.feature_point_selection(\n",
    "            frame,\n",
    "            mask=roi_mask,\n",
    "            quality_level=quality_level,\n",
    "            quality_level_rv=quality_level_rv,\n",
    "        )\n",
    "\n",
    "    return feature_points"
   ],
   "id": "1181686524c00053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def extract_feature_point_movement(frames: np.ndarray, feature_points: np.ndarray) -> np.ndarray:\n",
    "    lk_params = {\n",
    "        'winSize': hyperparameters['OFP_winSize'],\n",
    "        'maxLevel': hyperparameters['OFP_maxLevel'],\n",
    "    }\n",
    "    total_frame = len(frames)\n",
    "\n",
    "    # Store the feature points for each frame\n",
    "    feature_point_matrix = np.zeros((int(total_frame), feature_points.shape[0], 2))\n",
    "\n",
    "    # Store the feature points for the first frame\n",
    "    feature_point_matrix[0, :, 0] = feature_points[:, 0, 0].T\n",
    "    feature_point_matrix[0, :, 1] = feature_points[:, 0, 1].T\n",
    "\n",
    "    # Calculate the optical flow of the feature points for each frame\n",
    "    for inx in range(1, total_frame):\n",
    "        current_frame = frames[inx - 1]\n",
    "        next_frame = frames[inx]\n",
    "\n",
    "        new_positions, _, _ = cv2.calcOpticalFlowPyrLK(\n",
    "            current_frame,\n",
    "            next_frame,\n",
    "            feature_points,\n",
    "            None,\n",
    "            **lk_params)\n",
    "\n",
    "        feature_points = new_positions.reshape(-1, 1, 2)\n",
    "        feature_point_matrix[inx, :, 0] = feature_points[:, 0, 0].T\n",
    "        feature_point_matrix[inx, :, 1] = feature_points[:, 0, 1].T\n",
    "\n",
    "    return feature_point_matrix"
   ],
   "id": "eb7db35a92ff393e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_respiratory_signal(\n",
    "        frames: np.ndarray,\n",
    "        fps: int,\n",
    "        quality_level=float(0.3),\n",
    "        strategy=FeaturePointStrategy.default,\n",
    "        use_cgof=False,\n",
    "        use_filter=True,\n",
    "        use_normalization=False,\n",
    ") -> np.ndarray:\n",
    "    feature_points = get_feature_points(\n",
    "        frames[0],\n",
    "        strategy=strategy,\n",
    "        quality_level=quality_level)\n",
    "\n",
    "    # Extract the movement of the feature points for each frame\n",
    "    feature_point_movements = extract_feature_point_movement(frames, feature_points)\n",
    "\n",
    "    # Calculate the amplitude of the feature points for each frame\n",
    "    point_amplitudes = np.sqrt(feature_point_movements[:, :, 0] ** 2 + feature_point_movements[:, :, 1] ** 2)\n",
    "\n",
    "    # Calculate the amplitude of the feature points for each frame\n",
    "    respiratory_signal = np.sum(point_amplitudes, 1) / point_amplitudes.shape[1]\n",
    "\n",
    "    # Correlation-Guided Optical Flow Method\n",
    "    if use_cgof:\n",
    "        respiratory_signal = optical_flow.correlation_guided_optical_flow_method(point_amplitudes, respiratory_signal)\n",
    "\n",
    "    # Butterworth Filter\n",
    "    if use_filter:\n",
    "        respiratory_signal = optical_flow.butterworth_filter(\n",
    "            respiratory_signal,\n",
    "            fps,\n",
    "            lowpass=hyperparameters['Filter_LowPass'],\n",
    "            highpass=hyperparameters['Filter_HighPass'],\n",
    "        )\n",
    "\n",
    "    # Normalization\n",
    "    if use_normalization:\n",
    "        respiratory_signal = optical_flow.normalize_signal(respiratory_signal)\n",
    "\n",
    "    return respiratory_signal"
   ],
   "id": "2838be0bad9eca4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "breathing_signal_roi = extract_respiratory_signal(\n",
    "    subject_frames,\n",
    "    params.fps,\n",
    "    quality_level=hyperparameters['OFP_qualityLevel'],\n",
    "    strategy=FeaturePointStrategy.roi,\n",
    "    use_cgof=True,\n",
    "    use_filter=True,\n",
    "    use_normalization=True,\n",
    ")"
   ],
   "id": "d4e7ef615d5afdfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(y=breathing_signal_roi, title='Respiratory Signal')\n",
    "fig.show()"
   ],
   "id": "fd12a9046a2dc331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "get_ground_truth_rr = dataset.get_ground_truth_rr(subject, scenario)\n",
    "get_ground_truth_rr, get_ground_truth_rr * 60"
   ],
   "id": "9ab2751948c6f9a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for fp_strategy in tqdm(FeaturePointStrategy):\n",
    "    breathing_signal = extract_respiratory_signal(\n",
    "        subject_frames,\n",
    "        params.fps,\n",
    "        quality_level=hyperparameters['OFP_qualityLevel'],\n",
    "        strategy=fp_strategy,\n",
    "        use_cgof=True,\n",
    "        use_filter=True,\n",
    "        use_normalization=True,\n",
    "    )\n",
    "\n",
    "    extraction = optical_flow.FrequencyExtraction(breathing_signal, params.fps)\n",
    "\n",
    "    evaluation_results[fp_strategy] = {\n",
    "        'FFT ': extraction.fft(),\n",
    "        'PC': extraction.peak_counting(),\n",
    "        'CP': extraction.crossing_point(),\n",
    "        'NFCP': extraction.negative_feedback_crossover_point_method()\n",
    "    }"
   ],
   "id": "175368ef91733e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation_rows = []\n",
    "\n",
    "for fp_strategy, methods in evaluation_results.items():\n",
    "    for method, value in methods.items():\n",
    "        evaluation_rows.append({\n",
    "            'fp_strategy': fp_strategy.value,\n",
    "            'method': method,\n",
    "            'respiration_frequency': value,\n",
    "            'respiration_rate': value * 60,\n",
    "            'error': abs(get_ground_truth_rr * 60 - value * 60),\n",
    "        })\n",
    "\n",
    "evaluation = pd.DataFrame(evaluation_rows)\n",
    "evaluation"
   ],
   "id": "ce74cf8b6ec65d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the error for each Strategy and Method\n",
    "fig, axs = plt.subplots(1, len(FeaturePointStrategy), figsize=(15, 5))\n",
    "\n",
    "for idx, fp_strategy in enumerate(FeaturePointStrategy):\n",
    "    strategy_evaluation = evaluation[evaluation['fp_strategy'] == fp_strategy.value]\n",
    "\n",
    "    axs[idx].bar(strategy_evaluation['method'], strategy_evaluation['error'])\n",
    "    axs[idx].set_title(f'{fp_strategy}')\n",
    "    axs[idx].set_ylabel('Error (BPM)')\n",
    "\n",
    "plt.show()"
   ],
   "id": "2589f69d5bcc4dfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "old_gray = subject_frames[0]\n",
    "\n",
    "default_points = optical_flow.feature_point_selection(old_gray, mask=None)\n",
    "special_points = optical_flow.special_feature_point_selection(old_gray, mask=None)\n",
    "\n",
    "subject_roi = find_roi(old_gray)\n",
    "# subject_roi_mask = utils.roi_to_mask(old_gray, subject_roi)\n",
    "# \n",
    "# roi_points = optical_flow.feature_point_selection(old_gray, mask=subject_roi_mask)\n",
    "# special_roi = optical_flow.special_feature_point_selection(old_gray, mask=subject_roi_mask)\n",
    "\n",
    "print(f'Feature Points: {default_points.shape[0]}')\n",
    "print(f'Special Points: {special_points.shape[0]}')\n",
    "# print(f'ROI Points: {roi_points.shape[0]}')\n",
    "# print(f'Special ROI Points: {special_roi.shape[0]}')\n",
    "\n",
    "# Plot the first frame with the feature points\n",
    "plt.imshow(old_gray, cmap='gray')\n",
    "\n",
    "# Draw the region of interest (ROI)\n",
    "roi_x, roi_y, roi_w, roi_h = subject_roi\n",
    "plt.gca().add_patch(plt.Rectangle(\n",
    "    (roi_x, roi_y), roi_w, roi_h,\n",
    "    linewidth=1, edgecolor='r', facecolor='none'))\n",
    "\n",
    "for iny in range(default_points.shape[0]):\n",
    "    plt.scatter(default_points[iny, 0, 0],\n",
    "                default_points[iny, 0, 1],\n",
    "                c='r', s=2.5)\n",
    "\n",
    "for iny in range(special_points.shape[0]):\n",
    "    plt.scatter(special_points[iny, 0, 0],\n",
    "                special_points[iny, 0, 1],\n",
    "                c='b', s=2.5)\n",
    "\n",
    "# for iny in range(roi_points.shape[0]):\n",
    "#     plt.scatter(roi_points[iny, 0, 0],\n",
    "#                 roi_points[iny, 0, 1],\n",
    "#                 c='#FFFF00', s=2.5)\n",
    "# \n",
    "# for iny in range(special_roi.shape[0]):\n",
    "#     plt.scatter(special_roi[iny, 0, 0],\n",
    "#                 special_roi[iny, 0, 1],\n",
    "#                 c='#FF00FF', s=2.5)\n",
    "\n",
    "plt.show()"
   ],
   "id": "9a88ee3df7f80324",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
