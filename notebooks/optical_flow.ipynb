{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import respiratory_extraction.utils as utils\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), '..', 'data', 'subjects')\n",
    "dataset = utils.Dataset(data_path)\n",
    "\n",
    "subject = 'Proband16'\n",
    "scenario = '101_natural_lighting'\n",
    "\n",
    "frames, params = dataset.read_video_bgr(subject, scenario)"
   ],
   "id": "38877d9593e0b11c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    'OFP_maxCorners': 100,\n",
    "    'OFP_qualityLevel': 0.1,\n",
    "    'OFP_minDistance': 7,\n",
    "    'OFP_mask': None,\n",
    "    'OFP_QualityLevelRV': 0.05,\n",
    "    'OFP_winSize': (15, 15),\n",
    "    'OFP_maxLevel': 2,\n",
    "    'FSS_switch': False,\n",
    "    'FSS_maxCorners': 100,\n",
    "    'FSS_qualityLevel': 0.1,\n",
    "    'FSS_minDistance': 7,\n",
    "    'FSS_mask': None,\n",
    "    'FSS_QualityLevelRV': 0.05,\n",
    "    'FSS_FPN': 5,\n",
    "    'CGOF_switch': False,\n",
    "    'Filter_switch': False,\n",
    "    'Filter_type': 'bandpass',\n",
    "    'Filter_order': 3,\n",
    "    'Filter_LowPass': 2,\n",
    "    'Filter_HighPass': 40,\n",
    "    'Normalization_switch': False,\n",
    "    'RR_switch': False,\n",
    "    'RR_Algorithm_PC_Height': None,\n",
    "    'RR_Algorithm_PC_Threshold': None,\n",
    "    'RR_Algorithm_PC_MaxRR': 45,\n",
    "    'RR_Algorithm_CP_shfit_distance': 15,\n",
    "    'RR_Algorithm_NFCP_shfit_distance': 15,\n",
    "    'RR_Algorithm_NFCP_qualityLevel': 0.6\n",
    "}"
   ],
   "id": "eb6298885b947e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "class RRAlgorithm:\n",
    "    def __init__(self, respiratory_signal: np.ndarray, fs: float):\n",
    "        self.data = respiratory_signal\n",
    "        self.fs = fs\n",
    "        self.N = len(respiratory_signal)\n",
    "        self.Time = self.N / fs\n",
    "\n",
    "    def fft(self) -> float:\n",
    "        \"\"\"\n",
    "        Fast Fourier Transform\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        fft_y = fft(self.data)\n",
    "        abs_y = np.abs(fft_y)\n",
    "        normalization_y = abs_y / self.N\n",
    "        normalization_half_y = normalization_y[range(int(self.N / 2))]\n",
    "        sorted_indices = np.argsort(normalization_half_y)\n",
    "\n",
    "        max_frequency = self.fs\n",
    "        f = np.linspace(0, max_frequency, self.N)\n",
    "        return f[sorted_indices[-2]]\n",
    "\n",
    "    def peak_counting(self,\n",
    "                      height=hyperparameters['RR_Algorithm_PC_Height'],\n",
    "                      threshold=hyperparameters['RR_Algorithm_PC_Threshold'],\n",
    "                      max_rr=hyperparameters['RR_Algorithm_PC_MaxRR']\n",
    "                      ) -> float:\n",
    "        \"\"\"\n",
    "        Peak Counting Method\n",
    "        :param height:\n",
    "        :param threshold:\n",
    "        :param max_rr:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        distance = 60 / max_rr * self.fs\n",
    "\n",
    "        peaks, _ = find_peaks(\n",
    "            self.data,\n",
    "            height=height,\n",
    "            threshold=threshold,\n",
    "            distance=distance)\n",
    "\n",
    "        return len(peaks) / self.Time\n",
    "\n",
    "    def crossing_point(self) -> float:\n",
    "        \"\"\"\n",
    "        Crossing Point Method\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        shift_distance = int(self.fs / 2)\n",
    "        data_shift = np.zeros(self.data.shape) - 1\n",
    "        data_shift[shift_distance:] = self.data[:-shift_distance]\n",
    "        cross_curve = self.data - data_shift\n",
    "\n",
    "        zero_number = 0\n",
    "        zero_index = []\n",
    "        for inx in range(len(cross_curve) - 1):\n",
    "            if cross_curve[inx] == 0:\n",
    "                zero_number += 1\n",
    "                zero_index.append(inx)\n",
    "            else:\n",
    "                if cross_curve[inx] * cross_curve[inx + 1] < 0:\n",
    "                    zero_number += 1\n",
    "                    zero_index.append(inx)\n",
    "\n",
    "        return (zero_number / 2) / (self.N / self.fs)\n",
    "\n",
    "    def negative_feedback_crossover_point_method(\n",
    "            self,\n",
    "            quality_level=hyperparameters['RR_Algorithm_NFCP_qualityLevel']\n",
    "    ) -> float:\n",
    "        shift_distance = int(self.fs / 2)\n",
    "        data_shift = np.zeros(self.data.shape) - 1\n",
    "        data_shift[shift_distance:] = self.data[:-shift_distance]\n",
    "        cross_curve = self.data - data_shift\n",
    "\n",
    "        zero_number = 0\n",
    "        zero_index = []\n",
    "        for i in range(len(cross_curve) - 1):\n",
    "            if cross_curve[i] == 0:\n",
    "                zero_number += 1\n",
    "                zero_index.append(i)\n",
    "            else:\n",
    "                if cross_curve[i] * cross_curve[i + 1] < 0:\n",
    "                    zero_number += 1\n",
    "                    zero_index.append(i)\n",
    "\n",
    "        rr_tmp = ((zero_number / 2) / (self.N / self.fs))\n",
    "\n",
    "        if len(zero_index) <= 1:\n",
    "            return rr_tmp\n",
    "\n",
    "        time_span = 60 / rr_tmp / 2 * self.fs * quality_level\n",
    "        zero_span = []\n",
    "        for i in range(len(zero_index) - 1):\n",
    "            zero_span.append(zero_index[i + 1] - zero_index[i])\n",
    "\n",
    "        while min(zero_span) < time_span:\n",
    "            doubt_point = np.argmin(zero_span)\n",
    "            zero_index.pop(doubt_point)\n",
    "            zero_index.pop(doubt_point)\n",
    "            if len(zero_index) <= 1:\n",
    "                break\n",
    "            zero_span = []\n",
    "            for i in range(len(zero_index) - 1):\n",
    "                zero_span.append(zero_index[i + 1] - zero_index[i])\n",
    "\n",
    "        return (zero_number / 2) / (self.N / self.fs)"
   ],
   "id": "4acb5dae0e015cd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1181686524c00053",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from scipy import signal\n",
    "\n",
    "\n",
    "# Formally called FeaturePointSelectionStrategy...\n",
    "def special_feature_point_selection(frame, fpn=5, quality_level=0.3):\n",
    "    feature_params = {\n",
    "        'maxCorners': hyperparameters['FSS_maxCorners'],\n",
    "        'qualityLevel': quality_level,\n",
    "        'minDistance': hyperparameters['FSS_minDistance']\n",
    "    }\n",
    "    points = cv2.goodFeaturesToTrack(\n",
    "        frame,\n",
    "        mask=hyperparameters['FSS_mask'],\n",
    "        **feature_params)\n",
    "\n",
    "    while points is None:\n",
    "        feature_params['qualityLevel'] = quality_level - hyperparameters['FSS_QualityLevelRV']\n",
    "        points = cv2.goodFeaturesToTrack(frame, mask=None, **feature_params)\n",
    "\n",
    "    if len(points) < fpn:\n",
    "        fpn = len(points)\n",
    "\n",
    "    h = frame.shape[0] / 2\n",
    "    w = frame.shape[1] / 2\n",
    "\n",
    "    # TODO: Figure out how the top points are selected...\n",
    "    p1 = points.copy()\n",
    "    p1[:, :, 0] -= w\n",
    "    p1[:, :, 1] -= h\n",
    "    p1_1 = np.multiply(p1, p1)\n",
    "    p1_2 = np.sum(p1_1, 2)\n",
    "    p1_3 = np.sqrt(p1_2)\n",
    "    p1_4 = p1_3[:, 0]\n",
    "    p1_5 = np.argsort(p1_4)\n",
    "\n",
    "    fp_map = np.zeros((fpn, 1, 2), dtype=np.float32)\n",
    "    for inx in range(fpn):\n",
    "        fp_map[inx, :, :] = points[p1_5[inx], :, :]\n",
    "\n",
    "    return fp_map\n",
    "\n",
    "\n",
    "def default_feature_point_selection(frame, quality_level=0.3):\n",
    "    feature_params = {\n",
    "        'maxCorners': hyperparameters['OFP_maxCorners'],\n",
    "        'qualityLevel': quality_level,\n",
    "        'minDistance': hyperparameters['OFP_minDistance']\n",
    "    }\n",
    "    points = cv2.goodFeaturesToTrack(frame, mask=hyperparameters['OFP_mask'], **feature_params)\n",
    "\n",
    "    while points is None:\n",
    "        feature_params['qualityLevel'] = quality_level - hyperparameters['OFP_QualityLevelRV']\n",
    "        points = cv2.goodFeaturesToTrack(\n",
    "            frame,\n",
    "            mask=hyperparameters['OFP_mask'],\n",
    "            **feature_params)\n",
    "\n",
    "    return points"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Figure out what this does...\n",
    "def correlation_guided_optical_flow_method(point_amplitudes: np.ndarray, respiratory_signal: np.ndarray) -> np.ndarray:\n",
    "    point_amplitudes_t = np.array(point_amplitudes).T\n",
    "\n",
    "    augmented_matrix = np.zeros((point_amplitudes_t.shape[0] + 1, point_amplitudes_t.shape[1]))\n",
    "    augmented_matrix[0, :] = respiratory_signal\n",
    "    augmented_matrix[1:, :] = point_amplitudes_t\n",
    "\n",
    "    correlation_matrix = np.corrcoef(augmented_matrix)\n",
    "\n",
    "    cm_mean = np.mean(abs(correlation_matrix[0, 1:]))\n",
    "\n",
    "    quality_num = np.array(abs(correlation_matrix[0, 1:]) >= cm_mean).sum()\n",
    "    quality_feature_point_arg = np.array(abs(correlation_matrix[0, 1:]) >= cm_mean).argsort()[0 - quality_num:]\n",
    "\n",
    "    cgof_matrix = np.zeros((point_amplitudes.shape[0], quality_num))\n",
    "\n",
    "    for idx in range(quality_num):\n",
    "        cgof_matrix[:, idx] = point_amplitudes[:, quality_feature_point_arg[idx]]\n",
    "\n",
    "    return np.sum(cgof_matrix, 1) / quality_num"
   ],
   "id": "2b1af3e7e99bb523",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_feature_point_movement(\n",
    "        frames: np.ndarray,\n",
    "        quality_level=float(0.3),\n",
    "        use_fft=False,\n",
    ") -> np.ndarray:\n",
    "    current_frame = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # FeaturePoint Selection Strategy\n",
    "    if use_fft:\n",
    "        feature_points = special_feature_point_selection(\n",
    "            current_frame,\n",
    "            fpn=hyperparameters['FSS_FPN'],\n",
    "            quality_level=hyperparameters['FSS_qualityLevel']\n",
    "        )\n",
    "    else:\n",
    "        feature_points = default_feature_point_selection(\n",
    "            current_frame,\n",
    "            quality_level=quality_level\n",
    "        )\n",
    "\n",
    "    lk_params = {\n",
    "        'winSize': hyperparameters['OFP_winSize'],\n",
    "        'maxLevel': hyperparameters['OFP_maxLevel'],\n",
    "    }\n",
    "    total_frame = len(frames)\n",
    "\n",
    "    # Store the feature points for each frame\n",
    "    feature_point_matrix = np.zeros((int(total_frame), feature_points.shape[0], 2))\n",
    "\n",
    "    # Store the feature points for the first frame\n",
    "    feature_point_matrix[0, :, 0] = feature_points[:, 0, 0].T\n",
    "    feature_point_matrix[0, :, 1] = feature_points[:, 0, 1].T\n",
    "\n",
    "    # Calculate the optical flow of the feature points for each frame\n",
    "    for inx, frame in enumerate(frames[1:], start=1):\n",
    "        next_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_positions, _, _ = cv2.calcOpticalFlowPyrLK(\n",
    "            current_frame,\n",
    "            next_frame,\n",
    "            feature_points,\n",
    "            None,\n",
    "            **lk_params)\n",
    "\n",
    "        current_frame = next_frame.copy()\n",
    "\n",
    "        feature_points = new_positions.reshape(-1, 1, 2)\n",
    "        feature_point_matrix[inx, :, 0] = feature_points[:, 0, 0].T\n",
    "        feature_point_matrix[inx, :, 1] = feature_points[:, 0, 1].T\n",
    "\n",
    "    return feature_point_matrix\n",
    "\n",
    "\n",
    "def extract_respiratory_signal(\n",
    "        frames: np.ndarray,\n",
    "        fps: int,\n",
    "        quality_level=float(0.3),\n",
    "        use_fft=False,\n",
    "        use_cgof=False,\n",
    "        use_filter=True,\n",
    "        use_normalization=False,\n",
    ") -> np.ndarray:\n",
    "    # Store the feature points for each frame\n",
    "    feature_point_matrix = extract_feature_point_movement(\n",
    "        frames,\n",
    "        quality_level=quality_level,\n",
    "        use_fft=use_fft,\n",
    "    )\n",
    "\n",
    "    # Calculate the amplitude of the feature points for each frame\n",
    "    point_amplitudes = np.sqrt(feature_point_matrix[:, :, 0] ** 2 + feature_point_matrix[:, :, 1] ** 2)\n",
    "\n",
    "    # Calculate the amplitude of the feature points for each frame\n",
    "    respiratory_signal = np.sum(point_amplitudes, 1) / point_amplitudes.shape[1]\n",
    "\n",
    "    # Correlation-Guided Optical Flow Method\n",
    "    if use_cgof:\n",
    "        respiratory_signal = correlation_guided_optical_flow_method(point_amplitudes, respiratory_signal)\n",
    "\n",
    "    if use_filter:\n",
    "        original_signal = respiratory_signal\n",
    "        filter_order = hyperparameters['Filter_order']\n",
    "        lowpass = hyperparameters['Filter_LowPass'] / 60\n",
    "        highpass = hyperparameters['Filter_HighPass'] / 60\n",
    "        b, a = signal.butter(filter_order, [2 * lowpass / fps, 2 * highpass / fps], hyperparameters['Filter_type'])\n",
    "        respiratory_signal_filtered = signal.filtfilt(b, a, original_signal)\n",
    "    else:\n",
    "        respiratory_signal_filtered = respiratory_signal\n",
    "\n",
    "    if use_normalization:\n",
    "        max_ampl = max(respiratory_signal_filtered)\n",
    "        min_ampl = min(respiratory_signal_filtered)\n",
    "        respiratory_signal_norm = (respiratory_signal_filtered - min_ampl) / (max_ampl - min_ampl) - 0.5\n",
    "    else:\n",
    "        respiratory_signal_norm = respiratory_signal_filtered\n",
    "\n",
    "    return respiratory_signal_norm"
   ],
   "id": "2838be0bad9eca4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "breathing_signal = extract_respiratory_signal(\n",
    "    frames,\n",
    "    params.fps,\n",
    "    quality_level=hyperparameters['OFP_qualityLevel'],\n",
    "    use_fft=True,\n",
    "    use_cgof=True,\n",
    "    use_filter=True,\n",
    "    use_normalization=True,\n",
    ")"
   ],
   "id": "d4e7ef615d5afdfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(y=breathing_signal, title='Respiratory Signal')\n",
    "fig.show()"
   ],
   "id": "fd12a9046a2dc331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# RR Evaluation\n",
    "RR_method = RRAlgorithm(breathing_signal, params.fps)\n",
    "RR_FFT = RR_method.fft()\n",
    "RR_PC = RR_method.peak_counting()\n",
    "RR_CP = RR_method.crossing_point()\n",
    "RR_NFCP = RR_method.negative_feedback_crossover_point_method()\n",
    "\n",
    "get_ground_truth_rr = dataset.get_ground_truth_rr(subject, scenario)\n",
    "\n",
    "print(f'Ground Truth: {round(get_ground_truth_rr * 60, 1)}')\n",
    "print(f'FFT: {round(RR_FFT * 60, 1)}')\n",
    "print(f'Peak Counting: {round(RR_PC * 60, 1)}')\n",
    "print(f'Crossing Point: {round(RR_CP * 60, 1)}')\n",
    "print(f'Negative Feedback Crossover Point: {round(RR_NFCP * 60, 1)}')"
   ],
   "id": "6b6e7f3e6b048154",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "old_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "default_points = default_feature_point_selection(\n",
    "    old_gray,\n",
    "    quality_level=hyperparameters['FSS_qualityLevel'])\n",
    "\n",
    "special_points = special_feature_point_selection(\n",
    "    old_gray,\n",
    "    fpn=hyperparameters['FSS_FPN'],\n",
    "    quality_level=hyperparameters['FSS_qualityLevel'])\n",
    "\n",
    "print(default_points.shape)\n",
    "print(special_points.shape)\n",
    "\n",
    "# Plot the first frame with the feature points\n",
    "plt.imshow(old_gray, cmap='gray')\n",
    "for iny in range(default_points.shape[0]):\n",
    "    plt.scatter(default_points[iny, 0, 0], default_points[iny, 0, 1], c='r')\n",
    "\n",
    "for iny in range(special_points.shape[0]):\n",
    "    plt.scatter(special_points[iny, 0, 0], special_points[iny, 0, 1], c='b')\n",
    "\n",
    "plt.show()"
   ],
   "id": "9a88ee3df7f80324",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
