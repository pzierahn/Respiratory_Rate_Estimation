{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import respiratory_extraction.utils as utils\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), '..', 'data', 'subjects')\n",
    "dataset = utils.Dataset(data_path)\n",
    "\n",
    "subject = 'Proband05'\n",
    "scenario = '101_natural_lighting'\n",
    "\n",
    "subject_frames, params = dataset.read_video_bgr(subject, scenario)"
   ],
   "id": "38877d9593e0b11c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    'OFP_maxCorners': 100,\n",
    "    'OFP_qualityLevel': 0.1,\n",
    "    'OFP_minDistance': 7,\n",
    "    'OFP_mask': None,\n",
    "    'OFP_QualityLevelRV': 0.05,\n",
    "    'OFP_winSize': (15, 15),\n",
    "    'OFP_maxLevel': 2,\n",
    "    'FSS_maxCorners': 100,\n",
    "    'FSS_qualityLevel': 0.1,\n",
    "    'FSS_minDistance': 7,\n",
    "    'FSS_mask': None,\n",
    "    'FSS_QualityLevelRV': 0.05,\n",
    "    'FSS_FPN': 5,\n",
    "    'Filter_order': 3,\n",
    "    'Filter_LowPass': 0.1,\n",
    "    'Filter_HighPass': 0.6,\n",
    "    'RR_Algorithm_PC_Height': None,\n",
    "    'RR_Algorithm_PC_Threshold': None,\n",
    "    'RR_Algorithm_PC_MaxRR': 45,\n",
    "    'RR_Algorithm_NFCP_qualityLevel': 0.6\n",
    "}"
   ],
   "id": "eb6298885b947e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import respiratory_extraction.models.baseline as baseline\n",
    "\n",
    "\n",
    "def find_roi(frame: np.ndarray) -> tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Find the region of interest (ROI) based on the face detection\n",
    "    :param frame: The frame to find the ROI\n",
    "    :return: The region of interest (ROI) coordinates (x, y, w, h)\n",
    "    \"\"\"\n",
    "\n",
    "    faces = baseline.face_detection(frame)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        raise ValueError('No face detected in the first frame')\n",
    "    elif len(faces) > 1:\n",
    "        raise ValueError('Multiple faces detected in the first frame')\n",
    "\n",
    "    # First face position and size\n",
    "    x, y, w, h = faces[0]\n",
    "\n",
    "    scale_x = int(w * 0.2)\n",
    "\n",
    "    # Calculate the region of interest (ROI) based on the face\n",
    "    chest_x = x - scale_x\n",
    "    chest_y = int(y + h + h * 0.7)\n",
    "    chest_w = w + scale_x * 2\n",
    "    chest_h = int(h * 0.5)\n",
    "\n",
    "    return chest_x, chest_y, chest_w, chest_h"
   ],
   "id": "434449646062376d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.fftpack import fft\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "class RRAlgorithm:\n",
    "    def __init__(self, respiratory_signal: np.ndarray, fs: float):\n",
    "        self.data = respiratory_signal\n",
    "        self.fs = fs\n",
    "        self.N = len(respiratory_signal)\n",
    "        self.Time = self.N / fs\n",
    "\n",
    "    def fft(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the respiratory frequency using the Fast Fourier Transform (FFT)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        fft_y = fft(self.data)\n",
    "        abs_y = np.abs(fft_y)\n",
    "        normalization_y = abs_y / self.N\n",
    "        normalization_half_y = normalization_y[range(int(self.N / 2))]\n",
    "        sorted_indices = np.argsort(normalization_half_y)\n",
    "\n",
    "        max_frequency = self.fs\n",
    "        f = np.linspace(0, max_frequency, self.N)\n",
    "        return f[sorted_indices[-2]]\n",
    "\n",
    "    def peak_counting(self,\n",
    "                      height=hyperparameters['RR_Algorithm_PC_Height'],\n",
    "                      threshold=hyperparameters['RR_Algorithm_PC_Threshold'],\n",
    "                      max_rr=hyperparameters['RR_Algorithm_PC_MaxRR']\n",
    "                      ) -> float:\n",
    "        \"\"\"\n",
    "        Peak Counting Method\n",
    "        :param height:\n",
    "        :param threshold:\n",
    "        :param max_rr:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        distance = 60 / max_rr * self.fs\n",
    "\n",
    "        peaks, _ = find_peaks(\n",
    "            self.data,\n",
    "            height=height,\n",
    "            threshold=threshold,\n",
    "            distance=distance)\n",
    "\n",
    "        return len(peaks) / self.Time\n",
    "\n",
    "    def crossing_point(self) -> float:\n",
    "        \"\"\"\n",
    "        Crossing Point Method\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        shift_distance = int(self.fs / 2)\n",
    "        data_shift = np.zeros(self.data.shape) - 1\n",
    "        data_shift[shift_distance:] = self.data[:-shift_distance]\n",
    "        cross_curve = self.data - data_shift\n",
    "\n",
    "        zero_number = 0\n",
    "        zero_index = []\n",
    "        for inx in range(len(cross_curve) - 1):\n",
    "            if cross_curve[inx] == 0:\n",
    "                zero_number += 1\n",
    "                zero_index.append(inx)\n",
    "            else:\n",
    "                if cross_curve[inx] * cross_curve[inx + 1] < 0:\n",
    "                    zero_number += 1\n",
    "                    zero_index.append(inx)\n",
    "\n",
    "        return (zero_number / 2) / (self.N / self.fs)\n",
    "\n",
    "    def negative_feedback_crossover_point_method(\n",
    "            self,\n",
    "            quality_level=hyperparameters['RR_Algorithm_NFCP_qualityLevel']\n",
    "    ) -> float:\n",
    "        shift_distance = int(self.fs / 2)\n",
    "        data_shift = np.zeros(self.data.shape) - 1\n",
    "        data_shift[shift_distance:] = self.data[:-shift_distance]\n",
    "        cross_curve = self.data - data_shift\n",
    "\n",
    "        zero_number = 0\n",
    "        zero_index = []\n",
    "        for i in range(len(cross_curve) - 1):\n",
    "            if cross_curve[i] == 0:\n",
    "                zero_number += 1\n",
    "                zero_index.append(i)\n",
    "            else:\n",
    "                if cross_curve[i] * cross_curve[i + 1] < 0:\n",
    "                    zero_number += 1\n",
    "                    zero_index.append(i)\n",
    "\n",
    "        rr_tmp = ((zero_number / 2) / (self.N / self.fs))\n",
    "\n",
    "        if len(zero_index) <= 1:\n",
    "            return rr_tmp\n",
    "\n",
    "        time_span = 60 / rr_tmp / 2 * self.fs * quality_level\n",
    "        zero_span = []\n",
    "        for i in range(len(zero_index) - 1):\n",
    "            zero_span.append(zero_index[i + 1] - zero_index[i])\n",
    "\n",
    "        while min(zero_span) < time_span:\n",
    "            doubt_point = np.argmin(zero_span)\n",
    "            zero_index.pop(doubt_point)\n",
    "            zero_index.pop(doubt_point)\n",
    "            if len(zero_index) <= 1:\n",
    "                break\n",
    "            zero_span = []\n",
    "            for i in range(len(zero_index) - 1):\n",
    "                zero_span.append(zero_index[i + 1] - zero_index[i])\n",
    "\n",
    "        return (zero_number / 2) / (self.N / self.fs)"
   ],
   "id": "4acb5dae0e015cd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1181686524c00053",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from scipy import signal\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class FeaturePointStrategy(Enum):\n",
    "    special = 'ffs'\n",
    "    default = 'default'\n",
    "    roi = 'roi'\n",
    "    special_roi = 'special_roi'\n",
    "\n",
    "\n",
    "# Formally called FeaturePointSelectionStrategy...\n",
    "def special_feature_point_selection(frame, fpn=5, quality_level=0.3):\n",
    "    feature_params = {\n",
    "        'maxCorners': hyperparameters['FSS_maxCorners'],\n",
    "        'qualityLevel': quality_level,\n",
    "        'minDistance': hyperparameters['FSS_minDistance']\n",
    "    }\n",
    "    points = cv2.goodFeaturesToTrack(\n",
    "        frame,\n",
    "        mask=hyperparameters['FSS_mask'],\n",
    "        **feature_params)\n",
    "\n",
    "    while points is None:\n",
    "        feature_params['qualityLevel'] = quality_level - hyperparameters['FSS_QualityLevelRV']\n",
    "        points = cv2.goodFeaturesToTrack(frame, mask=None, **feature_params)\n",
    "\n",
    "    if len(points) < fpn:\n",
    "        fpn = len(points)\n",
    "\n",
    "    h = frame.shape[0] / 2\n",
    "    w = frame.shape[1] / 2\n",
    "\n",
    "    # TODO: Figure out how the top points are selected...\n",
    "    p1 = points.copy()\n",
    "    p1[:, :, 0] -= w\n",
    "    p1[:, :, 1] -= h\n",
    "    p1_1 = np.multiply(p1, p1)\n",
    "    p1_2 = np.sum(p1_1, 2)\n",
    "    p1_3 = np.sqrt(p1_2)\n",
    "    p1_4 = p1_3[:, 0]\n",
    "    p1_5 = np.argsort(p1_4)\n",
    "\n",
    "    fp_map = np.zeros((fpn, 1, 2), dtype=np.float32)\n",
    "    for inx in range(fpn):\n",
    "        fp_map[inx, :, :] = points[p1_5[inx], :, :]\n",
    "\n",
    "    return fp_map\n",
    "\n",
    "\n",
    "def default_feature_point_selection(frame, quality_level=0.3):\n",
    "    feature_params = {\n",
    "        'maxCorners': hyperparameters['OFP_maxCorners'],\n",
    "        'qualityLevel': quality_level,\n",
    "        'minDistance': hyperparameters['OFP_minDistance']\n",
    "    }\n",
    "    points = cv2.goodFeaturesToTrack(frame, mask=hyperparameters['OFP_mask'], **feature_params)\n",
    "\n",
    "    while points is None:\n",
    "        feature_params['qualityLevel'] = quality_level - hyperparameters['OFP_QualityLevelRV']\n",
    "        points = cv2.goodFeaturesToTrack(\n",
    "            frame,\n",
    "            mask=hyperparameters['OFP_mask'],\n",
    "            **feature_params)\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def roi_feature_point_selection(frame: np.ndarray, roi: tuple[int, int, int, int], quality_level=float(0.3)):\n",
    "    feature_params = {\n",
    "        'maxCorners': hyperparameters['OFP_maxCorners'],\n",
    "        'qualityLevel': quality_level,\n",
    "        'minDistance': hyperparameters['OFP_minDistance']\n",
    "    }\n",
    "\n",
    "    # Create a mask for the region of interest coordinates (x, y, w, h)\n",
    "    roi_mask = np.zeros_like(frame)\n",
    "    roi_mask[roi[1]:roi[1] + roi[3], roi[0]:roi[0] + roi[2]] = 255\n",
    "\n",
    "    points = cv2.goodFeaturesToTrack(frame, mask=roi_mask, **feature_params)\n",
    "\n",
    "    while points is None:\n",
    "        feature_params['qualityLevel'] = quality_level - hyperparameters['OFP_QualityLevelRV']\n",
    "        points = cv2.goodFeaturesToTrack(\n",
    "            frame,\n",
    "            mask=hyperparameters['OFP_mask'],\n",
    "            **feature_params)\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def special_roi_feature_point_selection(frame: np.ndarray, roi: tuple[int, int, int, int], quality_level=float(0.3)):\n",
    "    feature_params = {\n",
    "        'maxCorners': hyperparameters['OFP_maxCorners'],\n",
    "        'qualityLevel': quality_level,\n",
    "        'minDistance': hyperparameters['OFP_minDistance']\n",
    "    }\n",
    "\n",
    "    # Create a mask for the region of interest coordinates (x, y, w, h)\n",
    "    roi_mask = np.zeros_like(frame)\n",
    "    roi_mask[roi[1]:roi[1] + roi[3], roi[0]:roi[0] + roi[2]] = 255\n",
    "\n",
    "    points = cv2.goodFeaturesToTrack(frame, mask=roi_mask, **feature_params)\n",
    "\n",
    "    while points is None:\n",
    "        feature_params['qualityLevel'] = quality_level - hyperparameters['OFP_QualityLevelRV']\n",
    "        points = cv2.goodFeaturesToTrack(frame, mask=roi, **feature_params)\n",
    "\n",
    "    fpn = 5\n",
    "    if len(points) < fpn:\n",
    "        fpn = len(points)\n",
    "\n",
    "    h = frame.shape[0] / 2\n",
    "    w = frame.shape[1] / 2\n",
    "\n",
    "    # TODO: Figure out how the top points are selected...\n",
    "    p1 = points.copy()\n",
    "    p1[:, :, 0] -= w\n",
    "    p1[:, :, 1] -= h\n",
    "    p1_1 = np.multiply(p1, p1)\n",
    "    p1_2 = np.sum(p1_1, 2)\n",
    "    p1_3 = np.sqrt(p1_2)\n",
    "    p1_4 = p1_3[:, 0]\n",
    "    p1_5 = np.argsort(p1_4)\n",
    "\n",
    "    fp_map = np.zeros((fpn, 1, 2), dtype=np.float32)\n",
    "    for inx in range(fpn):\n",
    "        fp_map[inx, :, :] = points[p1_5[inx], :, :]\n",
    "\n",
    "    return fp_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Figure out what this does...\n",
    "def correlation_guided_optical_flow_method(\n",
    "        point_amplitudes: np.ndarray,\n",
    "        respiratory_signal: np.ndarray) -> np.ndarray:\n",
    "    point_amplitudes_t = np.array(point_amplitudes).T\n",
    "\n",
    "    augmented_matrix = np.zeros((point_amplitudes_t.shape[0] + 1, point_amplitudes_t.shape[1]))\n",
    "    augmented_matrix[0, :] = respiratory_signal\n",
    "    augmented_matrix[1:, :] = point_amplitudes_t\n",
    "\n",
    "    correlation_matrix = np.corrcoef(augmented_matrix)\n",
    "\n",
    "    cm_mean = np.mean(abs(correlation_matrix[0, 1:]))\n",
    "\n",
    "    quality_num = np.array(abs(correlation_matrix[0, 1:]) >= cm_mean).sum()\n",
    "    quality_feature_point_arg = np.array(abs(correlation_matrix[0, 1:]) >= cm_mean).argsort()[0 - quality_num:]\n",
    "\n",
    "    cgof_matrix = np.zeros((point_amplitudes.shape[0], quality_num))\n",
    "\n",
    "    for idx in range(quality_num):\n",
    "        cgof_matrix[:, idx] = point_amplitudes[:, quality_feature_point_arg[idx]]\n",
    "\n",
    "    return np.sum(cgof_matrix, 1) / quality_num"
   ],
   "id": "2b1af3e7e99bb523",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_feature_point_movement(\n",
    "        frames: np.ndarray,\n",
    "        quality_level=float(0.3),\n",
    "        feature_point_strategy=FeaturePointStrategy.default,\n",
    ") -> np.ndarray:\n",
    "    current_frame = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # FeaturePoint Selection Strategy\n",
    "    if feature_point_strategy == FeaturePointStrategy.special:\n",
    "        feature_points = special_feature_point_selection(\n",
    "            current_frame,\n",
    "            fpn=hyperparameters['FSS_FPN'],\n",
    "            quality_level=hyperparameters['FSS_qualityLevel']\n",
    "        )\n",
    "    elif feature_point_strategy == FeaturePointStrategy.roi:\n",
    "        roi = find_roi(current_frame)\n",
    "        feature_points = roi_feature_point_selection(\n",
    "            current_frame,\n",
    "            roi,\n",
    "            quality_level=quality_level\n",
    "        )\n",
    "    elif feature_point_strategy == FeaturePointStrategy.special_roi:\n",
    "        roi = find_roi(current_frame)\n",
    "        feature_points = special_roi_feature_point_selection(\n",
    "            current_frame,\n",
    "            roi,\n",
    "            quality_level=quality_level\n",
    "        )\n",
    "    else:\n",
    "        feature_points = default_feature_point_selection(\n",
    "            current_frame,\n",
    "            quality_level=quality_level\n",
    "        )\n",
    "\n",
    "    lk_params = {\n",
    "        'winSize': hyperparameters['OFP_winSize'],\n",
    "        'maxLevel': hyperparameters['OFP_maxLevel'],\n",
    "    }\n",
    "    total_frame = len(frames)\n",
    "\n",
    "    # Store the feature points for each frame\n",
    "    feature_point_matrix = np.zeros((int(total_frame), feature_points.shape[0], 2))\n",
    "\n",
    "    # Store the feature points for the first frame\n",
    "    feature_point_matrix[0, :, 0] = feature_points[:, 0, 0].T\n",
    "    feature_point_matrix[0, :, 1] = feature_points[:, 0, 1].T\n",
    "\n",
    "    # Calculate the optical flow of the feature points for each frame\n",
    "    for inx, frame in enumerate(frames[1:], start=1):\n",
    "        next_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_positions, _, _ = cv2.calcOpticalFlowPyrLK(\n",
    "            current_frame,\n",
    "            next_frame,\n",
    "            feature_points,\n",
    "            None,\n",
    "            **lk_params)\n",
    "\n",
    "        current_frame = next_frame.copy()\n",
    "\n",
    "        feature_points = new_positions.reshape(-1, 1, 2)\n",
    "        feature_point_matrix[inx, :, 0] = feature_points[:, 0, 0].T\n",
    "        feature_point_matrix[inx, :, 1] = feature_points[:, 0, 1].T\n",
    "\n",
    "    return feature_point_matrix"
   ],
   "id": "eb7db35a92ff393e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_respiratory_signal(\n",
    "        frames: np.ndarray,\n",
    "        fps: int,\n",
    "        quality_level=float(0.3),\n",
    "        feature_point_strategy=FeaturePointStrategy.default,\n",
    "        use_cgof=False,\n",
    "        use_filter=True,\n",
    "        use_normalization=False,\n",
    ") -> np.ndarray:\n",
    "    # Store the feature points for each frame\n",
    "    feature_point_matrix = extract_feature_point_movement(\n",
    "        frames,\n",
    "        quality_level=quality_level,\n",
    "        feature_point_strategy=feature_point_strategy,\n",
    "    )\n",
    "\n",
    "    # Calculate the amplitude of the feature points for each frame\n",
    "    point_amplitudes = np.sqrt(feature_point_matrix[:, :, 0] ** 2 + feature_point_matrix[:, :, 1] ** 2)\n",
    "\n",
    "    # Calculate the amplitude of the feature points for each frame\n",
    "    respiratory_signal = np.sum(point_amplitudes, 1) / point_amplitudes.shape[1]\n",
    "\n",
    "    # Correlation-Guided Optical Flow Method\n",
    "    if use_cgof:\n",
    "        respiratory_signal = correlation_guided_optical_flow_method(point_amplitudes, respiratory_signal)\n",
    "\n",
    "    if use_filter:\n",
    "        original_signal = respiratory_signal\n",
    "        filter_order = hyperparameters['Filter_order']\n",
    "        lowpass = hyperparameters['Filter_LowPass']\n",
    "        highpass = hyperparameters['Filter_HighPass']\n",
    "\n",
    "        b, a, *_ = signal.butter(\n",
    "            filter_order,\n",
    "            # [2 * lowpass / fps, 2 * highpass / fps],\n",
    "            [lowpass / fps, highpass / fps],\n",
    "            output='ba',\n",
    "            btype='bandpass')\n",
    "        respiratory_signal_filtered = signal.filtfilt(b, a, original_signal)\n",
    "    else:\n",
    "        respiratory_signal_filtered = respiratory_signal\n",
    "\n",
    "    if use_normalization:\n",
    "        max_ampl = max(respiratory_signal_filtered)\n",
    "        min_ampl = min(respiratory_signal_filtered)\n",
    "        respiratory_signal_norm = (respiratory_signal_filtered - min_ampl) / (max_ampl - min_ampl) - 0.5\n",
    "    else:\n",
    "        respiratory_signal_norm = respiratory_signal_filtered\n",
    "\n",
    "    return respiratory_signal_norm"
   ],
   "id": "2838be0bad9eca4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "breathing_signal_roi = extract_respiratory_signal(\n",
    "    subject_frames,\n",
    "    params.fps,\n",
    "    quality_level=hyperparameters['OFP_qualityLevel'],\n",
    "    feature_point_strategy=FeaturePointStrategy.roi,\n",
    "    use_cgof=True,\n",
    "    use_filter=True,\n",
    "    use_normalization=True,\n",
    ")"
   ],
   "id": "d4e7ef615d5afdfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(y=breathing_signal_roi, title='Respiratory Signal')\n",
    "fig.show()"
   ],
   "id": "fd12a9046a2dc331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "get_ground_truth_rr = dataset.get_ground_truth_rr(subject, scenario)\n",
    "get_ground_truth_rr, get_ground_truth_rr * 60"
   ],
   "id": "9ab2751948c6f9a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for strategy in tqdm(FeaturePointStrategy):\n",
    "    breathing_signal = extract_respiratory_signal(\n",
    "        subject_frames,\n",
    "        params.fps,\n",
    "        quality_level=hyperparameters['OFP_qualityLevel'],\n",
    "        feature_point_strategy=strategy,\n",
    "        use_cgof=True,\n",
    "        use_filter=True,\n",
    "        use_normalization=True,\n",
    "    )\n",
    "\n",
    "    RR_method = RRAlgorithm(breathing_signal, params.fps)\n",
    "\n",
    "    evaluation_results[strategy] = {\n",
    "        'FFT ': RR_method.fft(),\n",
    "        'PC': RR_method.peak_counting(),\n",
    "        'CP': RR_method.crossing_point(),\n",
    "        'NFCP': RR_method.negative_feedback_crossover_point_method()\n",
    "    }"
   ],
   "id": "175368ef91733e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation_rows = []\n",
    "\n",
    "for strategy, methods in evaluation_results.items():\n",
    "    for method, value in methods.items():\n",
    "        evaluation_rows.append({\n",
    "            'Strategy': strategy,\n",
    "            'Method': method,\n",
    "            'Respiration_Frequency': value,\n",
    "            'Respiration_Rate': value * 60,\n",
    "            'Error': abs(get_ground_truth_rr * 60 - value * 60),\n",
    "        })\n",
    "\n",
    "evaluation = pd.DataFrame(evaluation_rows)\n",
    "evaluation"
   ],
   "id": "ce74cf8b6ec65d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the error for each Strategy and Method\n",
    "fig, axs = plt.subplots(1, len(FeaturePointStrategy), figsize=(15, 5))\n",
    "\n",
    "for idx, strategy in enumerate(FeaturePointStrategy):\n",
    "    strategy_evaluation = evaluation[evaluation['Strategy'] == strategy]\n",
    "\n",
    "    axs[idx].bar(strategy_evaluation['Method'], strategy_evaluation['Error'])\n",
    "    axs[idx].set_title(f'{strategy.value}')\n",
    "    axs[idx].set_ylabel('Error (bpm)')\n",
    "\n",
    "plt.show()"
   ],
   "id": "2589f69d5bcc4dfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "old_gray = cv2.cvtColor(subject_frames[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "default_points = default_feature_point_selection(\n",
    "    old_gray,\n",
    "    quality_level=hyperparameters['FSS_qualityLevel'])\n",
    "\n",
    "special_points = special_feature_point_selection(\n",
    "    old_gray,\n",
    "    fpn=hyperparameters['FSS_FPN'],\n",
    "    quality_level=hyperparameters['FSS_qualityLevel'])\n",
    "\n",
    "subject_roi = find_roi(old_gray)\n",
    "roi_points = roi_feature_point_selection(\n",
    "    old_gray,\n",
    "    subject_roi,\n",
    "    quality_level=hyperparameters['FSS_qualityLevel'])\n",
    "\n",
    "special_roi = special_roi_feature_point_selection(\n",
    "    old_gray,\n",
    "    subject_roi,\n",
    "    quality_level=hyperparameters['FSS_qualityLevel'])\n",
    "\n",
    "print(f'Feature Points: {default_points.shape[0]}')\n",
    "print(f'Special Points: {special_points.shape[0]}')\n",
    "print(f'ROI Points: {roi_points.shape[0]}')\n",
    "print(f'Special ROI Points: {special_roi.shape[0]}')\n",
    "\n",
    "# Plot the first frame with the feature points\n",
    "plt.imshow(old_gray, cmap='gray')\n",
    "for iny in range(default_points.shape[0]):\n",
    "    plt.scatter(default_points[iny, 0, 0],\n",
    "                default_points[iny, 0, 1],\n",
    "                c='r', s=2.5)\n",
    "\n",
    "for iny in range(special_points.shape[0]):\n",
    "    plt.scatter(special_points[iny, 0, 0],\n",
    "                special_points[iny, 0, 1],\n",
    "                c='b', s=2.5)\n",
    "\n",
    "for iny in range(roi_points.shape[0]):\n",
    "    plt.scatter(roi_points[iny, 0, 0],\n",
    "                roi_points[iny, 0, 1],\n",
    "                c='#FFFF00', s=2.5)\n",
    "\n",
    "for iny in range(special_roi.shape[0]):\n",
    "    plt.scatter(special_roi[iny, 0, 0],\n",
    "                special_roi[iny, 0, 1],\n",
    "                c='#FF00FF', s=2.5)\n",
    "\n",
    "plt.show()"
   ],
   "id": "9a88ee3df7f80324",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
