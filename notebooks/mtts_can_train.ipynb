{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "\n",
    "# The first 3 subjects are used for training\n",
    "training_subjects = dataset.get_subjects()[:-1]\n",
    "training_scenarios = [\n",
    "    '101_natural_lighting',\n",
    "    '103_abrupt_changing_lighting',\n",
    "]\n",
    "\n",
    "# The last 3 subjects are used for testing\n",
    "test_subjects = dataset.get_subjects()[-1:]\n",
    "test_scenarios = [\n",
    "    '101_natural_lighting',\n",
    "    '103_abrupt_changing_lighting',\n",
    "]"
   ],
   "id": "70605b936f8e538d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import keras\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from respiration.utils.unisens import VitalSigns\n",
    "from respiration.extractor.mtts_can import preprocess_video_frames\n",
    "import respiration.preprocessing as preprocessing\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "            self,\n",
    "            subjects: list[str],\n",
    "            scenarios: list[str],\n",
    "            frames_per_video: int,\n",
    "            dim: tuple[int, int] = (36, 36),\n",
    "            batch_size: int = 32,\n",
    "            frame_depth: int = 10,\n",
    "            shuffle: bool = True):\n",
    "        super(DataGenerator, self).__init__()\n",
    "\n",
    "        self.subjects = subjects\n",
    "        self.scenarios = scenarios\n",
    "        self.training_scenarios = list(itertools.product(subjects, scenarios))\n",
    "\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.frames_per_video = frames_per_video\n",
    "        self.frame_depth = frame_depth\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch\"\"\"\n",
    "        return math.ceil(len(self.training_scenarios) / self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Method called at the end of every epoch.\"\"\"\n",
    "        # TODO: Implement shuffle\n",
    "        pass\n",
    "\n",
    "    def get_ground_truths(self, subject: str, scenario: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get the respiration rate and pulse rate signals for a given subject and scenario.\n",
    "        :param subject: \n",
    "        :param scenario: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "\n",
    "        pulse_signal, _ = dataset.get_unisens_entry(subject, scenario, VitalSigns.pulse)\n",
    "        pulse_signal = resample(pulse_signal, self.frames_per_video)\n",
    "\n",
    "        rr_signal, _ = dataset.get_unisens_entry(subject, scenario, VitalSigns.thorax_abdomen)\n",
    "        rr_signal = resample(rr_signal, self.frames_per_video)\n",
    "\n",
    "        rr_signal = preprocessing.standard_processing(rr_signal, self.frames_per_video)\n",
    "        pulse_signal = preprocessing.standard_processing(pulse_signal, self.frames_per_video)\n",
    "\n",
    "        return rr_signal, pulse_signal\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the batch at position index\"\"\"\n",
    "\n",
    "        start = index * self.batch_size\n",
    "        end = min((index + 1) * self.batch_size, len(self.training_scenarios))\n",
    "        scenarios = self.training_scenarios[start:end]\n",
    "\n",
    "        x, y = self.__data_generation(scenarios)\n",
    "        return x, y\n",
    "\n",
    "    def __data_generation(self, scenarios: list[tuple[str, str]]):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "\n",
    "        # The model expects a number of frames that is a multiple of frame_depth\n",
    "\n",
    "        size = (self.frames_per_video // self.frame_depth) * self.frame_depth - self.frame_depth\n",
    "        size_all = len(scenarios) * size\n",
    "\n",
    "        # Create matrix to store the resized frames\n",
    "        resized_frames_training = np.zeros(\n",
    "            (size_all, self.dim[0], self.dim[1], 3),\n",
    "            dtype=np.float32)\n",
    "\n",
    "        # Create matrix to store the normalized frames\n",
    "        normalized_frames_training = np.zeros(\n",
    "            (size_all, self.dim[0], self.dim[1], 3),\n",
    "            dtype=np.float32)\n",
    "\n",
    "        pules_labels = np.zeros((size_all, 1), dtype=np.float32)\n",
    "        rr_labels = np.zeros((size_all, 1), dtype=np.float32)\n",
    "\n",
    "        for index, (subject, scenario) in enumerate(scenarios):\n",
    "            frames, meta = dataset.get_video_bgr(subject, scenario)\n",
    "            resized_frames, normalized_frames = preprocess_video_frames(frames, self.dim)\n",
    "\n",
    "            rr_signal, pules_signal = self.get_ground_truths(subject, scenario)\n",
    "\n",
    "            # The model expects to be divisible frame_depth\n",
    "            rr_signal, pules_signal = rr_signal[:size], pules_signal[:size]\n",
    "            resized_frames, normalized_frames = resized_frames[:size], normalized_frames[:size]\n",
    "\n",
    "            start_range = index * size\n",
    "            end_range = (index + 1) * size\n",
    "\n",
    "            rr_labels[start_range:end_range] = rr_signal.reshape(-1, 1)\n",
    "            pules_labels[start_range:end_range] = pules_signal.reshape(-1, 1)\n",
    "\n",
    "            resized_frames_training[start_range:end_range] = resized_frames\n",
    "            normalized_frames_training[start_range:end_range] = normalized_frames\n",
    "\n",
    "        output = (resized_frames_training, normalized_frames_training)\n",
    "        label = (pules_labels, rr_labels)\n",
    "\n",
    "        return output, label"
   ],
   "id": "8bab846606a009b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7076f62ccb18711",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(100)  # for reproducibility\n",
    "keras.backend.clear_session()\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# number of convolutional filters to use\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "\n",
    "dropout_rate1 = 0.25\n",
    "dropout_rate2 = 0.5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# number of dense units\n",
    "nb_dense = 128\n",
    "\n",
    "nb_epoch = 24\n",
    "nb_task = 12\n",
    "\n",
    "# frame_depth for CAN_3D, TS_CAN, Hybrid_CAN\n",
    "frame_depth = 10\n",
    "\n",
    "# CAN, MT_CAN, CAN_3D, MT_CAN_3D, Hybrid_CAN, MT_Hybrid_CAN, TS_CAN, MTTS_CAN\n",
    "temporal = 'MTTS_CAN'\n",
    "\n",
    "# train with resp or not\n",
    "respiration = True"
   ],
   "id": "8f95117487502011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.extractor.mtts_can.mtts_can import mtts_can\n",
    "from scipy.io import savemat\n",
    "\n",
    "\n",
    "def train(img_rows=36, img_cols=36):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "        batch_size = 6  # 12, 16, 32\n",
    "\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "        model = mtts_can(\n",
    "            frame_depth,\n",
    "            nb_filters1,\n",
    "            nb_filters2,\n",
    "            input_shape,\n",
    "            dropout_rate1=dropout_rate1,\n",
    "            dropout_rate2=dropout_rate2,\n",
    "            nb_dense=nb_dense)\n",
    "\n",
    "        optimizer = keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "        losses = {\n",
    "            'output_1': 'mean_squared_error',\n",
    "            'output_2': 'mean_squared_error',\n",
    "        }\n",
    "        loss_weights = {\n",
    "            'output_1': 1.0,\n",
    "            'output_2': 1.0,\n",
    "        }\n",
    "\n",
    "        model.compile(loss=losses, loss_weights=loss_weights, optimizer=optimizer)\n",
    "\n",
    "        # Create data generators\n",
    "        training_generator = DataGenerator(\n",
    "            training_subjects,\n",
    "            training_scenarios,\n",
    "            3600,\n",
    "            (img_rows, img_cols),\n",
    "            batch_size=batch_size,\n",
    "            frame_depth=frame_depth,\n",
    "        )\n",
    "        validation_generator = DataGenerator(\n",
    "            test_subjects,\n",
    "            test_scenarios,\n",
    "            3600,\n",
    "            (img_rows, img_cols),\n",
    "            batch_size=batch_size,\n",
    "            frame_depth=frame_depth)\n",
    "\n",
    "        # Checkpoint Folders\n",
    "        checkpoint_folder = os.path.join('..', 'models', 'mtts_can')\n",
    "        cv_split_path = os.path.join(checkpoint_folder, 'checkpoint')\n",
    "        if not os.path.exists(cv_split_path):\n",
    "            os.makedirs(cv_split_path)\n",
    "\n",
    "        save_best_callback = keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(cv_split_path, 'last_model.keras'),\n",
    "            save_best_only=True,\n",
    "            verbose=1)\n",
    "\n",
    "        csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "            filename=os.path.join(cv_split_path, 'train_loss_log.csv'),\n",
    "        )\n",
    "\n",
    "        # Model Training and Saving Results\n",
    "        history = model.fit(\n",
    "            x=training_generator,\n",
    "            validation_data=validation_generator,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            shuffle=False,\n",
    "            callbacks=[csv_logger, save_best_callback],\n",
    "            validation_freq=4)\n",
    "\n",
    "        val_loss_history = history.history['val_loss']\n",
    "        val_loss = np.array(val_loss_history)\n",
    "        np.savetxt((cv_split_path + '_val_loss_log.csv'), val_loss, delimiter=\",\")\n",
    "\n",
    "        score = model.evaluate_generator(generator=validation_generator, verbose=1)\n",
    "\n",
    "        print('****************************************')\n",
    "        print('Average Test Score: ', score[0])\n",
    "        print('PPG Test Score: ', score[1])\n",
    "        print('Respiration Test Score: ', score[2])\n",
    "        print('****************************************')\n",
    "        print('Start saving predicitions from the last epoch')\n",
    "\n",
    "        yp_train = model.predict(training_generator, verbose=1)\n",
    "        savemat(\n",
    "            os.path.join(checkpoint_folder, 'train_best_' + '_cv.mat'),\n",
    "            mdict={'yptrain': yp_train})\n",
    "\n",
    "        yp_test = model.predict(validation_generator, verbose=1)\n",
    "        savemat(\n",
    "            os.path.join(checkpoint_folder, 'test_best_' + '_cv.mat'),\n",
    "            mdict={'yptest': yp_test})\n",
    "\n",
    "        print('Finish saving the results from the last epoch')"
   ],
   "id": "989c21cd2908d694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "train()",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
