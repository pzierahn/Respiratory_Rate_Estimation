{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# rPPG Predictions\n",
    "\n",
    "This notebook runs various pretrained models from [rPPG-Toolbox](https://github.com/ubicomplab/rPPG-Toolbox) to extract rPPG signals from videos. The rPPG signals are then saved to disk for further analysis."
   ],
   "id": "d6b5056fdfa6d020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import respiration.utils as utils\n",
    "\n",
    "dim = 72\n",
    "device = utils.get_torch_device()\n",
    "\n",
    "# Models are trained on different datasets\n",
    "models = {\n",
    "    'TS-CAN': [\n",
    "        'BP4D_PseudoLabel_TSCAN',\n",
    "        'MA-UBFC_tscan',\n",
    "        'PURE_TSCAN',\n",
    "        'SCAMPS_TSCAN',\n",
    "        'UBFC-rPPG_TSCAN',\n",
    "    ],\n",
    "    'DeepPhys': [\n",
    "        'BP4D_PseudoLabel_DeepPhys',\n",
    "        'MA-UBFC_deepphys',\n",
    "        'PURE_DeepPhys',\n",
    "        'SCAMPS_DeepPhys',\n",
    "        'UBFC-rPPG_DeepPhys',\n",
    "    ],\n",
    "}"
   ],
   "id": "64744f27d1a01020",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.extractor.ts_can import TSCAN\n",
    "from respiration.extractor.deep_phys import DeepPhys\n",
    "\n",
    "\n",
    "def load_model(name, path) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Load a pretrained model from the rPPG-Toolbox.\n",
    "    \"\"\"\n",
    "    match name:\n",
    "        case 'DeepPhys':\n",
    "            loaded_model = DeepPhys(img_size=dim).to(device)\n",
    "        case 'TS-CAN':\n",
    "            loaded_model = TSCAN(img_size=dim).to(device)\n",
    "        case _:\n",
    "            raise ValueError(f'Unknown model: {name}')\n",
    "\n",
    "    loaded_model = torch.nn.DataParallel(loaded_model).to(device)\n",
    "    loaded_model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def frames_preprocessing(name: str, frames: np.ndarray):\n",
    "    raw, diff = utils.preprocess_video_frames(frames, dim)\n",
    "\n",
    "    # Permute from (T, H, W, C) to (T, C, H, W)\n",
    "    raw = torch.tensor(raw).permute(0, 3, 1, 2).to(device)\n",
    "    diff = torch.tensor(diff).permute(0, 3, 1, 2).to(device)\n",
    "\n",
    "    # Concatenate the two inputs\n",
    "    combined = torch.cat((diff, raw), dim=1).to(device)\n",
    "\n",
    "    # TS-CAN requires the input to be a multiple of frame-depth (20)\n",
    "    if name == 'TS-CAN':\n",
    "        cut_off = (raw.shape[0] // 20) * 20\n",
    "        combined = combined[:cut_off]\n",
    "\n",
    "    return combined"
   ],
   "id": "d2958b0b9246d65b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])"
   ],
   "id": "472f67021320abc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    print(f'Processing: {subject} {setting}')\n",
    "    frames, meta = dataset.get_video_rgb(subject, setting)\n",
    "\n",
    "    for model_name, model_version in models.items():\n",
    "        for model in model_version:\n",
    "            print(f'--> {model_name} {model}')\n",
    "            model_path = utils.file_path('data', 'rPPG-Toolbox', model + '.pth')\n",
    "            model = load_model(model_name, model_path)\n",
    "\n",
    "            input_frames = frames_preprocessing(model_name, frames)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model(input_frames)\n",
    "\n",
    "            prediction = prediction.cpu().numpy().squeeze()\n",
    "\n",
    "            predictions.append({\n",
    "                'model_name': model_name,\n",
    "                'model': model_version,\n",
    "                'subject': subject,\n",
    "                'setting': setting,\n",
    "                'sampling_rate': meta.fps,\n",
    "                'signal': prediction.tolist(),\n",
    "            })"
   ],
   "id": "db49e068f8bde082",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "df.head()"
   ],
   "id": "60c46b662672a01f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "signals_dir = utils.dir_path('outputs', 'signals', mkdir=True)\n",
    "signals_path = utils.join_paths(signals_dir, 'r_ppg_predictions.csv')\n",
    "df.to_csv(signals_path, index=False)"
   ],
   "id": "972909c25da0739b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
