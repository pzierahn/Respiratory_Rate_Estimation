{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e8feb5a154ad",
   "metadata": {},
   "source": [
    "# Supervised\n",
    "\n",
    "This notebook extracts respiration signals with the following models:\n",
    "- MTTS-CAN\n",
    "- BigSmall"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import respiration.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])\n",
    "scenarios"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_dir = os.path.join(os.getcwd(), '..', 'evaluation', 'pretrained')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "id": "95937112f7167b53",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conduct experiments",
   "id": "e47aef2d563c7065"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "evaluation_metadata = {\n",
    "    'timestamp_start': datetime.now(),\n",
    "    'scenarios': scenarios,\n",
    "}"
   ],
   "id": "d6e2ab154d5334d9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "device = utils.get_torch_device()"
   ],
   "id": "55a8e929f87924fc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2aba3e680aa178da",
   "metadata": {},
   "source": [
    "from respiration.extractor.mtts_can import (\n",
    "    load_model,\n",
    "    calculate_cutoff,\n",
    "    preprocess_video_frames,\n",
    ")\n",
    "import respiration.extractor.big_small as big_small\n",
    "\n",
    "extracted_signals = []\n",
    "\n",
    "frame_depth = 10\n",
    "mtts_model = load_model(frame_depth=frame_depth)\n",
    "big_small_model, _ = big_small.load_model(device=device)\n",
    "\n",
    "for (subject, setting) in scenarios:\n",
    "    print(f'Processing {subject} - {setting}')\n",
    "\n",
    "    frames, meta = dataset.get_video_rgb(subject, setting)\n",
    "\n",
    "    #\n",
    "    # MTTS-CAN model to extract the signal\n",
    "    #\n",
    "\n",
    "    mtts_start = datetime.now()\n",
    "\n",
    "    resized, normalized = preprocess_video_frames(frames)\n",
    "    cutoff = calculate_cutoff(resized.shape[0], frame_depth)\n",
    "\n",
    "    resized = resized[:cutoff]\n",
    "    normalized = normalized[:cutoff]\n",
    "\n",
    "    mtts_raw = mtts_model.predict(\n",
    "        (resized, normalized),\n",
    "        batch_size=100\n",
    "    )\n",
    "    extracted_signals.append({\n",
    "        'subject': subject,\n",
    "        'setting': setting,\n",
    "        'model': 'mtts_can',\n",
    "        'duration': datetime.now() - mtts_start,\n",
    "        'sample_rate': meta.fps,\n",
    "        'signal': np.cumsum(mtts_raw[1]).tolist(),\n",
    "    })\n",
    "\n",
    "    #\n",
    "    # Use the BigSmall model to extract the signal\n",
    "    #\n",
    "    big_small_start = datetime.now()\n",
    "    big_small_raw = big_small.batch_process(big_small_model, frames, device)\n",
    "    extracted_signals.append({\n",
    "        'subject': subject,\n",
    "        'setting': setting,\n",
    "        'model': 'big_small',\n",
    "        'duration': datetime.now() - big_small_start,\n",
    "        'sample_rate': meta.fps,\n",
    "        'signal': big_small_raw.tolist(),\n",
    "    })\n",
    "\n",
    "    # Garbage collect the frames\n",
    "    del frames"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluation_metadata['timestamp_finish'] = datetime.now()",
   "id": "4361f0aa4df2465",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(extracted_signals)\n",
    "df.head()"
   ],
   "id": "e94ff7cb59c2a3ea",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the extracted_signals as a JSON\n",
    "json_path = os.path.join(results_dir, 'predictions.json')\n",
    "utils.write_json(json_path, extracted_signals)\n",
    "\n",
    "# Save the evaluation dataframe\n",
    "csv_path = os.path.join(results_dir, 'predictions.csv')\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Save the hyperparameters as prettified json\n",
    "json_path = os.path.join(results_dir, 'parameters.json')\n",
    "utils.write_json(json_path, evaluation_metadata)"
   ],
   "id": "3806544e615aa349",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
