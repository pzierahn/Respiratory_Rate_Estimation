{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformer",
   "id": "156541bc5c985cd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:57:04.611435Z",
     "start_time": "2024-05-13T06:57:02.995396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "tuned_models = {\n",
    "    # '20240511_190518',\n",
    "    # '20240511_194544',\n",
    "    '20240512_211825',\n",
    "}\n",
    "\n",
    "# Map model names to their paths\n",
    "models = {}\n",
    "\n",
    "manifests = []\n",
    "\n",
    "for model_id in tuned_models:\n",
    "    model_dir = utils.dir_path('models', 'transformer', model_id)\n",
    "\n",
    "    manifest_path = utils.dir_path(model_dir, 'manifest.json')\n",
    "    manifest = utils.read_json(manifest_path)\n",
    "    best_model = manifest['trained_models'][-1]\n",
    "\n",
    "    model_path = utils.join_paths(model_dir, best_model['model'])\n",
    "    models[model_id] = model_path\n",
    "    manifests.append(manifest)\n",
    "\n",
    "utils.pretty_print(models)"
   ],
   "id": "41913a5f51b91d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"20240512_211825\": \"/app/models/transformer/20240512_211825/20240512_211825_19.pth\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:57:04.652295Z",
     "start_time": "2024-05-13T06:57:04.612315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "image_size = 256"
   ],
   "id": "3eabcd4e01b673c5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:57:04.662924Z",
     "start_time": "2024-05-13T06:57:04.652895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def temporal_shifting_frames(frames: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the temporal shifting of the frames. This is done by calculating the difference between the frames and\n",
    "    normalizing the result.\n",
    "    \"\"\"\n",
    "    diff_frames = frames[1:] - frames[:-1]\n",
    "    sum_frames = frames[1:] + frames[:-1]\n",
    "    inputs = diff_frames / (sum_frames + 1e-7)\n",
    "    inputs = (inputs - torch.mean(inputs)) / torch.std(inputs)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def temporal_shifting_signal(time_series: torch.Tensor) -> torch.Tensor:\n",
    "    # Calculate the difference between the time series\n",
    "    return time_series[1:] - time_series[:-1]"
   ],
   "id": "5ff0d6db630bee5f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T07:02:56.674806Z",
     "start_time": "2024-05-13T06:57:04.663649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from vit_pytorch import ViT\n",
    "from torchvision import transforms\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    print(f\"Processing {subject} - {setting}\")\n",
    "\n",
    "    video_path = dataset.get_video_path(subject, setting)\n",
    "\n",
    "    frames, _ = utils.read_video_rgb(video_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    frames = torch.stack([preprocess(frame) for frame in frames], dim=0)\n",
    "    frames = frames.to(device)\n",
    "    frames = temporal_shifting_frames(frames)\n",
    "\n",
    "    for (model_id, model_path) in models.items():\n",
    "        print(f\"--> Using {model_id} model\")\n",
    "        # Wrap modul in nn.DataParallel to fix the model loading issue\n",
    "        model = ViT(\n",
    "            image_size=image_size,\n",
    "            patch_size=32,\n",
    "            num_classes=1,\n",
    "            dim=128,\n",
    "            depth=6,\n",
    "            heads=16,\n",
    "            mlp_dim=2048\n",
    "        ).to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(frames).cpu().detach().numpy().squeeze()\n",
    "\n",
    "        predictions.append({\n",
    "            'model': model_id,\n",
    "            'subject': subject,\n",
    "            'setting': setting,\n",
    "            'duration': dt.datetime.now() - start,\n",
    "            'signal': prediction.tolist(),\n",
    "        })\n",
    "\n",
    "    del frames\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Store the predictions to csv\n",
    "signals_dir = utils.dir_path('outputs', 'signals', mkdir=True)\n",
    "signals_path = utils.join_paths(signals_dir, 'transformer_predictions.csv')\n",
    "\n",
    "predictions.to_csv(signals_path, index=False)"
   ],
   "id": "44cbf5bc27ff119a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5543ff7516cb48f9a95bbd49a0ea1edb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Proband01 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband02 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband03 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband04 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband05 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband06 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband07 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband08 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband09 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband10 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband11 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband12 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband13 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband14 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband15 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband16 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband17 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband18 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband19 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband20 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband21 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband22 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband23 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband24 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband25 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n",
      "Processing Proband26 - 101_natural_lighting\n",
      "--> Using 20240512_211825 model\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T07:02:56.681209Z",
     "start_time": "2024-05-13T07:02:56.675304Z"
    }
   },
   "cell_type": "code",
   "source": "predictions.head()",
   "id": "ab2b7b98a1d93f49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             model    subject               setting               duration  \\\n",
       "0  20240512_211825  Proband01  101_natural_lighting 0 days 00:00:00.702146   \n",
       "1  20240512_211825  Proband02  101_natural_lighting 0 days 00:00:00.729610   \n",
       "2  20240512_211825  Proband03  101_natural_lighting 0 days 00:00:00.729791   \n",
       "3  20240512_211825  Proband04  101_natural_lighting 0 days 00:00:00.735905   \n",
       "4  20240512_211825  Proband05  101_natural_lighting 0 days 00:00:00.642627   \n",
       "\n",
       "                                              signal  \n",
       "0  [-0.001394517719745636, 0.005532152950763702, ...  \n",
       "1  [-0.0075696781277656555, 0.011222995817661285,...  \n",
       "2  [0.00974736362695694, 0.0017803534865379333, -...  \n",
       "3  [-0.006696484982967377, 0.005128942430019379, ...  \n",
       "4  [0.008742131292819977, -0.005681194365024567, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>subject</th>\n",
       "      <th>setting</th>\n",
       "      <th>duration</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240512_211825</td>\n",
       "      <td>Proband01</td>\n",
       "      <td>101_natural_lighting</td>\n",
       "      <td>0 days 00:00:00.702146</td>\n",
       "      <td>[-0.001394517719745636, 0.005532152950763702, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240512_211825</td>\n",
       "      <td>Proband02</td>\n",
       "      <td>101_natural_lighting</td>\n",
       "      <td>0 days 00:00:00.729610</td>\n",
       "      <td>[-0.0075696781277656555, 0.011222995817661285,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240512_211825</td>\n",
       "      <td>Proband03</td>\n",
       "      <td>101_natural_lighting</td>\n",
       "      <td>0 days 00:00:00.729791</td>\n",
       "      <td>[0.00974736362695694, 0.0017803534865379333, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240512_211825</td>\n",
       "      <td>Proband04</td>\n",
       "      <td>101_natural_lighting</td>\n",
       "      <td>0 days 00:00:00.735905</td>\n",
       "      <td>[-0.006696484982967377, 0.005128942430019379, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240512_211825</td>\n",
       "      <td>Proband05</td>\n",
       "      <td>101_natural_lighting</td>\n",
       "      <td>0 days 00:00:00.642627</td>\n",
       "      <td>[0.008742131292819977, -0.005681194365024567, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
