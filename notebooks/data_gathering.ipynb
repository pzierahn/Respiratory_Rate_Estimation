{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e8feb5a154ad",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "\n",
    "This notebook gathers the meta-data for the evaluation. It runs the various respiratory extraction methods."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import respiratory_extraction.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "subjects = dataset.get_subjects()\n",
    "subjects"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbaabf772d852710",
   "metadata": {},
   "source": [
    "# The scenarios in which the subjects were recorded\n",
    "# scenarios = dataset.get_scenarios()\n",
    "# scenarios = [\n",
    "#     '101_natural_lighting',\n",
    "#     # '102_artificial_lighting',\n",
    "#     '103_abrupt_changing_lighting',\n",
    "#     '104_dim_lighting_auto_exposure',\n",
    "#     # '106_green_lighting',\n",
    "#     # '107_infrared_lighting',\n",
    "#     '201_shouldercheck',\n",
    "#     '202_scale_movement',\n",
    "#     '203_translation_movement',\n",
    "#     # '204_writing'\n",
    "# ]\n",
    "scenarios = [\n",
    "    '101_natural_lighting',\n",
    "]\n",
    "scenarios"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "hyperparameters = {\n",
    "    'quality_level': 0.1,\n",
    "    'quality_level_rv': 0.05,\n",
    "}\n",
    "\n",
    "evaluation_metadata = {\n",
    "    'start_time': datetime.now(),\n",
    "    'subjects': subjects,\n",
    "    'scenarios': scenarios,\n",
    "}"
   ],
   "id": "d6e2ab154d5334d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiratory_extraction.utils.roi as roi\n",
    "\n",
    "yolo = roi.YOLO()\n",
    "\n",
    "\n",
    "def get_rois(frame: np.ndarray) -> list[tuple[np.ndarray, str]]:\n",
    "    \"\"\"\n",
    "    Get the regions of interest (ROIs) for the given frame\n",
    "    :param frame: The frame to get the ROIs from\n",
    "    :return: A list of tuples containing the ROI and the name of the ROI\n",
    "    \"\"\"\n",
    "\n",
    "    regions = [\n",
    "        # ROI for the full frame\n",
    "        ((0, 0, frame.shape[1], frame.shape[0]), 'full')\n",
    "    ]\n",
    "\n",
    "    # Calculate the region of interest (ROI) based on the face\n",
    "    faces = roi.detect_faces(frame)\n",
    "    if len(faces) == 1:\n",
    "        chest_roi = roi.roi_from_face(faces[0])\n",
    "        regions.append((chest_roi, 'chest'))\n",
    "\n",
    "    # Use the detected person to create a mask\n",
    "    persons = yolo.detect_classes(frame, clazz='person')\n",
    "    if len(persons) == 1:\n",
    "        regions.append((persons[0], 'person'))\n",
    "\n",
    "    return regions"
   ],
   "id": "ee5c3a836fc3fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2aba3e680aa178da",
   "metadata": {},
   "source": [
    "from respiratory_extraction.models.signal_extraction import pixel_intensity, optical_flow\n",
    "\n",
    "extracted_signals = []\n",
    "ground_truth_signals = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        print(f'Processing {subject} - {scenario}')\n",
    "\n",
    "        frames, params = dataset.read_video_gray(subject, scenario)\n",
    "\n",
    "        rois = get_rois(frames[0])\n",
    "\n",
    "        gt_signal, gt_sampling_rate = dataset.get_ground_truth_rr_signal(subject, scenario)\n",
    "        ground_truth_signals.append({\n",
    "            'subject': subject,\n",
    "            'scenario': scenario,\n",
    "            'signal': gt_signal.tolist(),\n",
    "            'sampling_rate': gt_sampling_rate,\n",
    "        })\n",
    "\n",
    "        for region in rois:\n",
    "            roi_area, roi_name = region\n",
    "\n",
    "            #\n",
    "            # Calculate the average pixel intensity\n",
    "            #\n",
    "\n",
    "            pi_start = datetime.now()\n",
    "            pi_signal = pixel_intensity.average_pixel_intensity(frames, roi=roi_area)\n",
    "            extracted_signals.append({\n",
    "                'subject': subject,\n",
    "                'scenario': scenario,\n",
    "                'method': 'pixel_intensity',\n",
    "                'parameters': {\n",
    "                    'roi': roi_name,\n",
    "                    'roi_area': list(roi_area),\n",
    "                },\n",
    "                'execution_time': datetime.now() - pi_start,\n",
    "                'sampling_rate': params.fps,\n",
    "                'signal': pi_signal.tolist(),\n",
    "            })\n",
    "\n",
    "            #\n",
    "            # Calculate the optical flow without cgof\n",
    "            # \n",
    "\n",
    "            of_raw_start = datetime.now()\n",
    "            of_signal_raw = optical_flow.extract_signal(\n",
    "                frames,\n",
    "                roi=roi_area,\n",
    "                quality_level=hyperparameters['quality_level'],\n",
    "                quality_level_rv=hyperparameters['quality_level_rv'],\n",
    "                use_cgof=False,\n",
    "            )\n",
    "            extracted_signals.append({\n",
    "                'subject': subject,\n",
    "                'scenario': scenario,\n",
    "                'method': 'optical_flow',\n",
    "                'parameters': {\n",
    "                    'roi': roi_name,\n",
    "                    'roi_area': list(roi_area),\n",
    "                    'quality_level': hyperparameters['quality_level'],\n",
    "                    'quality_level_rv': hyperparameters['quality_level_rv'],\n",
    "                    'use_cgof': False\n",
    "                },\n",
    "                'execution_time': datetime.now() - of_raw_start,\n",
    "                'sampling_rate': params.fps,\n",
    "                'signal': of_signal_raw.tolist(),\n",
    "            })\n",
    "\n",
    "            #\n",
    "            # Calculate the optical flow with cgof\n",
    "            #\n",
    "\n",
    "            of_cgof_start = datetime.now()\n",
    "            of_signal_raw = optical_flow.extract_signal(\n",
    "                frames,\n",
    "                roi=roi_area,\n",
    "                quality_level=hyperparameters['quality_level'],\n",
    "                quality_level_rv=hyperparameters['quality_level_rv'],\n",
    "                use_cgof=True,\n",
    "            )\n",
    "\n",
    "            extracted_signals.append({\n",
    "                'subject': subject,\n",
    "                'scenario': scenario,\n",
    "                'method': 'optical_flow',\n",
    "                'parameters': {\n",
    "                    'roi': roi_name,\n",
    "                    'roi_area': list(roi_area),\n",
    "                    'quality_level': hyperparameters['quality_level'],\n",
    "                    'quality_level_rv': hyperparameters['quality_level_rv'],\n",
    "                    'use_cgof': True\n",
    "                },\n",
    "                'execution_time': datetime.now() - of_cgof_start,\n",
    "                'sampling_rate': params.fps,\n",
    "                'signal': of_signal_raw.tolist(),\n",
    "            })\n",
    "\n",
    "        # Garbage collect the frames\n",
    "        del frames"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluation_metadata['end_time'] = datetime.now()",
   "id": "4361f0aa4df2465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(extracted_signals)\n",
    "df.head()"
   ],
   "id": "e94ff7cb59c2a3ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiratory_extraction.utils as utils\n",
    "\n",
    "evaluation_dir = os.path.join(os.getcwd(), '..', 'evaluation', 'signals')\n",
    "if not os.path.exists(evaluation_dir):\n",
    "    os.makedirs(evaluation_dir)\n",
    "\n",
    "# Save the extracted_signals as a JSON\n",
    "json_path = os.path.join(evaluation_dir, 'predictions.json')\n",
    "utils.write_json(json_path, extracted_signals)\n",
    "\n",
    "# Save the evaluation dataframe\n",
    "csv_path = os.path.join(evaluation_dir, 'predictions.csv')\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Save the hyperparameters as prettified json\n",
    "json_path = os.path.join(evaluation_dir, 'parameters.json')\n",
    "utils.write_json(json_path, evaluation_metadata)\n",
    "\n",
    "# Save the ground truth signals as a JSON\n",
    "json_path = os.path.join(evaluation_dir, 'ground_truth.json')\n",
    "utils.write_json(json_path, ground_truth_signals)\n",
    "\n",
    "# Save the ground truth signals as a CSV\n",
    "df_gt = pd.DataFrame(ground_truth_signals)\n",
    "csv_path = os.path.join(evaluation_dir, 'ground_truth.csv')\n",
    "df_gt.to_csv(csv_path, index=False)"
   ],
   "id": "3806544e615aa349",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
