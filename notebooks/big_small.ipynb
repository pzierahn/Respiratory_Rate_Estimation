{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "\n",
    "subject = 'Proband05'\n",
    "scenario = '101_natural_lighting'"
   ],
   "id": "4b78c47457679ff0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "frames, meta = dataset.get_video_rgb(subject, scenario)",
   "id": "a61011c940742495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "device"
   ],
   "id": "42faa5548dc370fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.extractor.big_small import *\n",
    "\n",
    "model, key_matching = load_model(device=device)\n",
    "key_matching"
   ],
   "id": "c4dc5f528d1e36c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.eval()",
   "id": "2b6a2d6c736de2a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.extractor.big_small import *\n",
    "\n",
    "# Get the first 10 seconds of the video\n",
    "big, small = preprocess_frames(frames[:300])"
   ],
   "id": "c9cfc5b066807c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show the first big and small frame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(small[1])\n",
    "axs[0].set_title('Small Frame')\n",
    "\n",
    "axs[1].imshow(big[1])\n",
    "axs[1].set_title('Big Frame')"
   ],
   "id": "798792a41bcdf4f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "big.shape, small.shape",
   "id": "2924d1f0ec731151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert the frames to a tensor\n",
    "small_tensor = torch.tensor(small, device=device)\n",
    "big_tensor = torch.tensor(big, device=device)"
   ],
   "id": "764f8da473b14cfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "small_tensor.shape, big_tensor.shape",
   "id": "573e06d38c7fe08c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Transform the tensor to the shape expected by the model (frame_count, c, w, h)\n",
    "small_tensor = small_tensor.permute(0, 3, 1, 2)\n",
    "big_tensor = big_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "small_tensor.shape, big_tensor.shape"
   ],
   "id": "f6e72af9225b6bed",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract the signals\n",
    "with torch.no_grad():\n",
    "    au_out, bvp_out, resp_out = model((big_tensor, small_tensor))\n",
    "\n",
    "resp_out.shape"
   ],
   "id": "f4da6f5049773234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.preprocessing as preprocessing\n",
    "\n",
    "waveform = resp_out.cpu().numpy().squeeze()\n",
    "waveform = preprocessing.detrend_tarvainen(waveform)\n",
    "waveform = preprocessing.butterworth_filter(waveform, meta.fps, 0.8, 3.0)"
   ],
   "id": "6ea84aca0bd934a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "waveform.shape",
   "id": "48877a36a2645e5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the rPPG signal\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(waveform)\n",
    "plt.title('Respiration Signal')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ],
   "id": "ef4da6e782ccaae9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "waveform = batch_process(model, frames, device, 360, True)",
   "id": "9a200c6cb67e2e1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "waveform_processed = preprocessing.detrend_tarvainen(waveform)\n",
    "waveform_processed = preprocessing.butterworth_filter(waveform_processed, meta.fps, 0.08, 0.6)"
   ],
   "id": "1b1ab5da1ce3c527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the signals\n",
    "_, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "axs[0].plot(waveform)\n",
    "axs[0].set_title('Signal')\n",
    "axs[0].set_xlabel('Frame')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "\n",
    "axs[1].plot(waveform_processed)\n",
    "axs[1].set_title('Processed')\n",
    "axs[1].set_xlabel('Frame')\n",
    "axs[1].set_ylabel('Amplitude')"
   ],
   "id": "84a82637ac3ef49d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.analysis as analysis\n",
    "\n",
    "# Compute the frequency\n",
    "analysis.frequency_from_nfcp(waveform_processed, meta.fps)"
   ],
   "id": "562ec2bf3803afbd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
