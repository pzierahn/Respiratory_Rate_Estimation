{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract respiratory signals with RAFT\n",
    "\n",
    "Recurrent All-Pairs Field Transforms (RAFT) is a deep learning model for optical flow estimation. The optical flow directions and magnitudes can be used to extract respiratory signals from videos. This notebook demonstrates how to use RAFT to extract respiratory signals from videos."
   ],
   "id": "e931c39f16bae87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "\n",
    "subject = 'Proband16'\n",
    "setting = '201_shouldercheck'\n",
    "\n",
    "video_path = dataset.get_video_path(subject, setting)"
   ],
   "id": "3f5527a9bf000",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import respiration.utils as utils\n",
    "import respiration.extractor.optical_flow_raft as raft\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "model = raft.load_model('raft_large', device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Number of frames that are processed at once\n",
    "batch_size = 10\n",
    "\n",
    "param = utils.get_video_params(video_path)\n",
    "\n",
    "# Set the number of frames to 30 * 6\n",
    "# param.num_frames = 30 * 6\n",
    "\n",
    "# Store the optical flows vectors (N, 2, H, W)\n",
    "optical_flows = np.zeros((param.num_frames, 2, param.height, param.width), dtype=np.float32)\n",
    "\n",
    "for start in tqdm(range(0, param.num_frames, batch_size)):\n",
    "    # Calculate the number of frames to process in this batch\n",
    "    num_frames = min(start + batch_size, param.num_frames) - start\n",
    "\n",
    "    frames, _ = utils.read_video_rgb(video_path, num_frames, start)\n",
    "    frames = raft.preprocess(frames, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Split the frames into odd and even frames to calculate optical flow on consecutive frames\n",
    "        flows = model(frames[::2], frames[1::2])\n",
    "\n",
    "    # Garbage collect...\n",
    "    del frames\n",
    "\n",
    "    # Only keep the last flow iteration\n",
    "    flows = flows[-1]\n",
    "\n",
    "    for idx in range(flows.shape[0]):\n",
    "        # Add the optical flow to the numpy array\n",
    "        optical_flows[start + idx] = flows[idx].cpu().numpy()"
   ],
   "id": "b12b8574e965cb28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_flow(img, flow, step=20):\n",
    "    \"\"\"\n",
    "    Plots the optical flow vectors on the image.\n",
    "    Args:\n",
    "    - img: The original image.\n",
    "    - flow: The optical flow vectors (HxWx2).\n",
    "    - step: Space between vectors to be drawn.\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step // 2:h:step, step // 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create an image to draw on\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Draw arrows\n",
    "    for (x0, y0, dx, dy) in zip(x, y, fx, fy):\n",
    "        # Length of the arrow is sqrt(dx^2 + dy^2)\n",
    "        # length = np.sqrt(dx ** 2 + dy ** 2)\n",
    "        # if length > 20:\n",
    "        #     continue\n",
    "\n",
    "        end_point = (int(x0 + dx), int(y0 + dy))\n",
    "        cv2.arrowedLine(\n",
    "            vis,\n",
    "            (x0, y0),\n",
    "            end_point,\n",
    "            color=(255, 0, 0),\n",
    "            thickness=1,\n",
    "            tipLength=0.25,\n",
    "        )\n",
    "\n",
    "    return vis\n",
    "\n",
    "\n",
    "def draw_flow_max(img, flow):\n",
    "    \"\"\"\n",
    "    Plots the optical flow vectors on the image.\n",
    "    Args:\n",
    "    - img: The original image.\n",
    "    - flow: The optical flow vectors (HxWx2).\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    fx, fy = flow[:, :, 0], flow[:, :, 1]\n",
    "\n",
    "    # Create an image to draw on\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Draw arrows\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            dx, dy = fx[y, x], fy[y, x]\n",
    "            end_point = (int(x + dx), int(y + dy))\n",
    "\n",
    "            # Length of the arrow is sqrt(dx^2 + dy^2)\n",
    "            length = np.sqrt(dx ** 2 + dy ** 2)\n",
    "            if length > 20:\n",
    "                continue\n",
    "\n",
    "            cv2.arrowedLine(\n",
    "                vis,\n",
    "                (x, y),\n",
    "                end_point,\n",
    "                color=(255, 0, 0),\n",
    "                thickness=1,\n",
    "                tipLength=0.25,\n",
    "            )\n",
    "\n",
    "    return vis\n",
    "\n",
    "\n",
    "def numpy_flow_to_image(flow: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts the optical flow vectors to an image.\n",
    "    Args:\n",
    "    - flow: The optical flow vectors (2xHxW).\n",
    "    \"\"\"\n",
    "    input = torch.from_numpy(flow).permute(2, 0, 1)\n",
    "    flow_image = flow_to_image(input)\n",
    "\n",
    "    return flow_image.numpy().transpose(1, 2, 0)"
   ],
   "id": "a388a602146cd29e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from torchvision.utils import flow_to_image\n",
    "\n",
    "arrow_video_path = '../../reports/videos/optical_flow_arrow.avi'\n",
    "arrow_video = cv2.VideoWriter(\n",
    "    arrow_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    param.fps,\n",
    "    (param.width, param.height))\n",
    "\n",
    "motion_video_path = '../../reports/videos/optical_flow_motion.avi'\n",
    "motion_video = cv2.VideoWriter(\n",
    "    motion_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    param.fps,\n",
    "    (param.width, param.height))\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "for idx in tqdm(range(param.num_frames)):\n",
    "    ret, frame_ = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    flow = optical_flows[idx].transpose(1, 2, 0)\n",
    "    frame = cv2.cvtColor(frame_, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    arrow_frame = draw_flow(frame, flow)\n",
    "    arrow_video.write(arrow_frame)\n",
    "\n",
    "    flow_frame = numpy_flow_to_image(flow)\n",
    "    motion_video.write(flow_frame)\n",
    "\n",
    "arrow_video.release()\n",
    "motion_video.release()\n",
    "cap.release()"
   ],
   "id": "90a0633ceb60337f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
