{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract respiratory signals with RAFT\n",
    "\n",
    "Recurrent All-Pairs Field Transforms (RAFT) is a deep learning model for optical flow estimation. The optical flow directions and magnitudes can be used to extract respiratory signals from videos. This notebook demonstrates how to use RAFT to extract respiratory signals from videos."
   ],
   "id": "e931c39f16bae87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "\n",
    "subject = 'Proband16'\n",
    "setting = '101_natural_lighting'\n",
    "\n",
    "video_path = dataset.get_video_path(subject, setting)"
   ],
   "id": "3f5527a9bf000",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import respiration.utils as utils\n",
    "import respiration.extractor.optical_flow_raft as raft\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "model = raft.load_model('raft_large', device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Number of frames that are processed at once\n",
    "batch_size = 10\n",
    "\n",
    "param = utils.get_video_params(video_path)\n",
    "\n",
    "# Make an empty numpy to store the optical flows in the N, 2, H, W format\n",
    "optical_flows = np.zeros((param.num_frames, 2, param.height, param.width), dtype=np.float32)\n",
    "\n",
    "for start in tqdm(range(0, param.num_frames, batch_size)):\n",
    "    # Calculate the number of frames to process in this batch\n",
    "    num_frames = min(start + batch_size, param.num_frames) - start\n",
    "\n",
    "    frames, _ = utils.read_video_rgb(video_path, num_frames, start)\n",
    "    frames = raft.preprocess(frames, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Split the frames into odd and even frames to calculate optical flow on consecutive frames\n",
    "        flows = model(frames[::2], frames[1::2])\n",
    "\n",
    "    # Garbage collect...\n",
    "    del frames\n",
    "\n",
    "    # Only keep the last flow iteration\n",
    "    flows = flows[-1]\n",
    "\n",
    "    for idx in range(flows.shape[0]):\n",
    "        # Add the optical flow to the numpy array\n",
    "        optical_flows[start + idx] = flows[idx].cpu().numpy()"
   ],
   "id": "b12b8574e965cb28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Store the optical_flows matrix to a file\n",
    "np.save('optical_flows.npy', optical_flows)"
   ],
   "id": "a0988e494a17dbc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
