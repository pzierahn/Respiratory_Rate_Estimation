{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract respiratory signals with RAFT\n",
    "\n",
    "Recurrent All-Pairs Field Transforms (RAFT) is a deep learning model for optical flow estimation. The optical flow directions and magnitudes can be used to extract respiratory signals from videos. This notebook demonstrates how to use RAFT to extract respiratory signals from videos."
   ],
   "id": "e931c39f16bae87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "subject = 'Proband16'\n",
    "setting = '101_natural_lighting'\n",
    "\n",
    "video_path = dataset.get_video_path(subject, setting)"
   ],
   "id": "3f5527a9bf000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the RAFT model",
   "id": "5b39d80a238d40de"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import respiration.utils as utils\n",
    "import respiration.extractor.optical_flow_raft as raft\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "model = raft.load_model('raft_small', device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract optical flow from the video",
   "id": "b67acd67436fb434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Number of frames that are processed at once\n",
    "batch_size = 10\n",
    "\n",
    "param = utils.get_video_params(video_path)\n",
    "\n",
    "# Only get the first 12 seconds of the video\n",
    "param.num_frames = param.fps * 4\n",
    "\n",
    "# Store the optical flows vectors (N, 2, H, W)\n",
    "optical_flows = np.zeros((param.num_frames, 2, param.height, param.width), dtype=np.float32)\n",
    "\n",
    "# Store the frames (N, H, W, 3)\n",
    "frames = np.zeros((param.num_frames, param.height, param.width, 3), dtype=np.uint8)\n",
    "\n",
    "# Extract the optical flow from the video in batches\n",
    "for start in tqdm(range(0, param.num_frames, batch_size)):\n",
    "    # Calculate the number of frames to process in this batch\n",
    "    num_frames = min(start + batch_size, param.num_frames) - start\n",
    "\n",
    "    chunk, _ = utils.read_video_rgb(video_path, num_frames, start)\n",
    "    frames[start:start + num_frames] = chunk\n",
    "\n",
    "    chunk = raft.preprocess(chunk, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Split the frames into odd and even frames to calculate optical flow on consecutive frames\n",
    "        flows = model(chunk[::2], chunk[1::2])\n",
    "\n",
    "    # Garbage collect...\n",
    "    del chunk\n",
    "\n",
    "    # Only keep the last flow iteration\n",
    "    flows = flows[-1]\n",
    "\n",
    "    for idx in range(flows.shape[0]):\n",
    "        # Add the optical flow to the numpy array\n",
    "        optical_flows[start + idx] = flows[idx].cpu().numpy()"
   ],
   "id": "b12b8574e965cb28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize the optical flow",
   "id": "30a9c0e9184db344"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arrow_frame = raft.draw_flow(frames[0], optical_flows[0])\n",
    "flow_frame = raft.image_from_flow(optical_flows[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax[0].imshow(arrow_frame)\n",
    "ax[0].set_title('Optical flow arrows')\n",
    "ax[1].imshow(flow_frame)\n",
    "ax[1].set_title('Optical flow magnitude')\n",
    "\n",
    "utils.store_figure(fig, 'raft', 'optical_flow')"
   ],
   "id": "186b18566a17c044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extract the respiratory signal\n",
    "\n",
    "1. Find the region of interest (ROI) on the chest\n",
    "2. Calculate the motion magnitude in the ROI\n",
    "3. Plot the motion magnitude over time"
   ],
   "id": "ecc392d0b46cfdc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.roi as roi\n",
    "\n",
    "# Find the chest region\n",
    "x, y, w, h = roi.detect_chest(frames[0])\n",
    "\n",
    "# Get only the optical flows in the chest region\n",
    "roi_flows = optical_flows[:, :, y:y + h, x:x + w]\n",
    "\n",
    "# Calculate motion magnitude by squaring the x and y components and taking the square root\n",
    "magnitudes = np.sqrt(np.sum(roi_flows ** 2, axis=(1, 2)))"
   ],
   "id": "d83c92695858709e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_curve = np.mean(magnitudes, axis=1)\n",
    "std_curve = np.std(magnitudes, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "ax.plot(mean_curve, label='Mean')\n",
    "ax.fill_between(\n",
    "    np.arange(len(mean_curve)),\n",
    "    mean_curve - std_curve,\n",
    "    mean_curve + std_curve,\n",
    "    alpha=0.3,\n",
    "    label='Standard deviation')\n",
    "ax.set_title('Motion magnitude in the ROI')\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Motion magnitude')\n",
    "\n",
    "utils.store_figure(fig, 'raft', 'roi_magnitudes')"
   ],
   "id": "2fc7bce9431aa25f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
