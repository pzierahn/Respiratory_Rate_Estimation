{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract respiratory signals with RAFT\n",
    "\n",
    "Recurrent All-Pairs Field Transforms (RAFT) is a deep learning model for optical flow estimation. The optical flow directions and magnitudes can be used to extract respiratory signals from videos. This notebook demonstrates how to use RAFT to extract respiratory signals from videos."
   ],
   "id": "e931c39f16bae87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])"
   ],
   "id": "3f5527a9bf000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "evaluation_dir = os.path.join('..', '..', 'evaluation', 'optical_flow_raft')\n",
    "os.makedirs(evaluation_dir, exist_ok=True)\n",
    "\n",
    "flows_dir = os.path.join(evaluation_dir, 'flows')\n",
    "os.makedirs(flows_dir, exist_ok=True)"
   ],
   "id": "ff44cce386692d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract optical flows",
   "id": "68dfab9c5a7fbad7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import respiration.utils as utils\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "\n",
    "raft_models = [\n",
    "    'raft_large',\n",
    "    'raft_small',\n",
    "]\n",
    "\n",
    "manifest = {\n",
    "    'timestamp_start': datetime.now(),\n",
    "    'scenarios': scenarios,\n",
    "    'device': device,\n",
    "    'raft_models': raft_models,\n",
    "    'flows': [],\n",
    "}"
   ],
   "id": "eb2f55e2aeddbde6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import respiration.extractor.optical_flow_raft as raft\n",
    "\n",
    "# Number of frames that are processed at once\n",
    "batch_size = 10\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    print(f'Processing {subject} - {setting}')\n",
    "\n",
    "    video_path = dataset.get_video_path(subject, setting)\n",
    "    param = utils.get_video_params(video_path)\n",
    "\n",
    "    for raft_model in raft_models:\n",
    "        model = raft.load_model(raft_model, device)\n",
    "\n",
    "        # Store the optical flows vectors (N, 2, H, W)\n",
    "        optical_flows = np.zeros((param.num_frames, 2, param.height, param.width), dtype=np.float32)\n",
    "\n",
    "        # Extract the optical flow from the video in batches\n",
    "        for start in range(0, param.num_frames, batch_size):\n",
    "            # Calculate the number of frames to process in this batch\n",
    "            num_frames = min(start + batch_size, param.num_frames) - start\n",
    "\n",
    "            chunk, _ = utils.read_video_rgb(video_path, num_frames, start)\n",
    "            chunk = raft.preprocess(chunk, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Split the frames into odd and even frames to calculate optical flow on consecutive frames\n",
    "                flows = model(chunk[::2], chunk[1::2])\n",
    "\n",
    "            # Garbage collect...\n",
    "            del chunk\n",
    "\n",
    "            # Only keep the last flow iteration\n",
    "            flows = flows[-1]\n",
    "\n",
    "            for idx in range(flows.shape[0]):\n",
    "                # Add the optical flow to the numpy array\n",
    "                optical_flows[start + idx] = flows[idx].cpu().numpy()\n",
    "\n",
    "        # Store the extracted signals\n",
    "        filename = f'{subject}_{setting}_{raft_model}.npy'\n",
    "        flow_file = os.path.join(flows_dir, filename)\n",
    "        np.save(flow_file, optical_flows)\n",
    "\n",
    "        # Garbage collect the optical flows (8.2GB)\n",
    "        del optical_flows\n",
    "\n",
    "        manifest['flows'].append({\n",
    "            'subject': subject,\n",
    "            'setting': setting,\n",
    "            'model': raft_model,\n",
    "            'filename': filename,\n",
    "        })"
   ],
   "id": "c54b105646357fb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "manifest['timestamp_finish'] = datetime.now()\n",
    "manifest_file = os.path.join(evaluation_dir, 'manifest.json')\n",
    "utils.write_json(manifest_file, manifest)"
   ],
   "id": "4ade1837050c82f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract respiratory signals",
   "id": "71b4a5c313f5d9c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ],
   "id": "6e4c1ecee4194875",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.roi as roi\n",
    "\n",
    "extracted_signals = []\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    for raft_model in raft_models:\n",
    "        filename = f'{subject}_{setting}_{raft_model}.npy'\n",
    "        flow_file = os.path.join(flows_dir, filename)\n",
    "        assert os.path.exists(flow_file)\n",
    "\n",
    "        optical_flows = np.load(flow_file)\n",
    "\n",
    "        first_frame = dataset.get_first_frame(subject, setting)\n",
    "        roi_areas = roi.get_roi_areas(first_frame)\n",
    "\n",
    "        for ((x, y, w, h), name) in roi_areas:\n",
    "            # Select the motion vectors in the region of interest\n",
    "            flow_region = optical_flows[:, :, y:y + h, x:x + w]\n",
    "\n",
    "            # Calculate the magnitudes of the motion vectors\n",
    "            magnitudes = np.sqrt(np.sum(flow_region ** 2, axis=(1, 2)))\n",
    "\n",
    "            # Calculate the mean and standard deviation of the magnitudes\n",
    "            mean_curve = np.mean(magnitudes, axis=1)\n",
    "            std_curve = np.std(magnitudes, axis=1)\n",
    "\n",
    "            extracted_signals.append({\n",
    "                'subject': subject,\n",
    "                'setting': setting,\n",
    "                'model': raft_model,\n",
    "                'roi': name,\n",
    "                'signal': mean_curve.tolist(),\n",
    "                'signal_std': std_curve.tolist(),\n",
    "            })\n",
    "\n",
    "        del optical_flows"
   ],
   "id": "ed2b36e28722b16e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "signals_df = pd.DataFrame(extracted_signals)\n",
    "predictions_file = os.path.join(evaluation_dir, 'predictions.csv')\n",
    "signals_df.to_csv(predictions_file, index=False)"
   ],
   "id": "9b4b207e7fe79198",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "signals_df.head()",
   "id": "fa3b70a86faefa49",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
