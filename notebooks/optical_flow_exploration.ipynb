{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiratory_extraction.dataset as repository\n",
    "\n",
    "dataset = repository.from_default()\n",
    "\n",
    "subject = 'Proband16'\n",
    "scenario = '101_natural_lighting'\n",
    "\n",
    "subject_frames, params = dataset.read_video_gray(subject, scenario)"
   ],
   "id": "38877d9593e0b11c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    'OFP_qualityLevel': 0.1,\n",
    "    'OFP_QualityLevelRV': 0.05,\n",
    "    'Filter_LowPass': 0.1,\n",
    "    'Filter_HighPass': 0.6,\n",
    "}"
   ],
   "id": "eb6298885b947e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import respiratory_extraction.utils as utils\n",
    "import respiratory_extraction.models.optical_flow as optical_flow\n",
    "\n",
    "\n",
    "def find_roi(frame: np.ndarray) -> tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Find the region of interest (ROI) based on the face detection\n",
    "    :param frame: The frame to find the ROI\n",
    "    :return: The region of interest (ROI) coordinates (x, y, w, h)\n",
    "    \"\"\"\n",
    "\n",
    "    faces = utils.detect_faces(frame)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        raise ValueError('No face detected in the first frame')\n",
    "    elif len(faces) > 1:\n",
    "        raise ValueError('Multiple faces detected in the first frame')\n",
    "\n",
    "    return utils.roi_from_face(faces[0], scale_w=0.2, scale_h=0.2)"
   ],
   "id": "434449646062376d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frame1 = subject_frames[0]\n",
    "subject_roi = find_roi(frame1)\n",
    "subject_roi_mask = utils.roi_to_mask(frame1, subject_roi)"
   ],
   "id": "57541859a60a4401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get different feature points for the first frame\n",
    "default_points = optical_flow.get_feature_points(frame1)\n",
    "special_points = optical_flow.get_feature_points(frame1, fpn=5)\n",
    "roi_points = optical_flow.get_feature_points(frame1, roi_mask=subject_roi_mask)\n",
    "special_roi = optical_flow.get_feature_points(frame1, roi_mask=subject_roi_mask, fpn=5)\n",
    "\n",
    "# Plot the first frame with the feature points\n",
    "plt.imshow(frame1, cmap='gray')\n",
    "\n",
    "# Draw the region of interest (ROI)\n",
    "roi_x, roi_y, roi_w, roi_h = subject_roi\n",
    "plt.gca().add_patch(plt.Rectangle(\n",
    "    (roi_x, roi_y), roi_w, roi_h,\n",
    "    linewidth=1, edgecolor='r', facecolor='none'))\n",
    "\n",
    "for iny in range(default_points.shape[0]):\n",
    "    plt.scatter(default_points[iny, 0, 0],\n",
    "                default_points[iny, 0, 1],\n",
    "                c='r', s=2.5)\n",
    "\n",
    "for iny in range(special_points.shape[0]):\n",
    "    plt.scatter(special_points[iny, 0, 0],\n",
    "                special_points[iny, 0, 1],\n",
    "                c='b', s=2.5)\n",
    "\n",
    "for iny in range(roi_points.shape[0]):\n",
    "    plt.scatter(roi_points[iny, 0, 0],\n",
    "                roi_points[iny, 0, 1],\n",
    "                c='#FFFF00', s=2.5)\n",
    "\n",
    "for iny in range(special_roi.shape[0]):\n",
    "    plt.scatter(special_roi[iny, 0, 0],\n",
    "                special_roi[iny, 0, 1],\n",
    "                c='#FF00FF', s=2.5)\n",
    "\n",
    "plt.show()"
   ],
   "id": "25fee91e19d2492f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_signal = optical_flow.extract_raw_signal(\n",
    "    subject_frames,\n",
    "    fpn=5,\n",
    "    quality_level=hyperparameters['OFP_qualityLevel'],\n",
    "    quality_level_rv=hyperparameters['OFP_QualityLevelRV'],\n",
    ")"
   ],
   "id": "d4e7ef615d5afdfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preprocessed_unprocessed = optical_flow.preprocess_signal(\n",
    "    raw_signal,\n",
    "    params.fps,\n",
    "    lowpass=hyperparameters['Filter_LowPass'],\n",
    "    highpass=hyperparameters['Filter_HighPass'],\n",
    ")\n",
    "\n",
    "signal_cgof = optical_flow.preprocess_signal(\n",
    "    raw_signal,\n",
    "    params.fps,\n",
    "    lowpass=hyperparameters['Filter_LowPass'],\n",
    "    highpass=hyperparameters['Filter_HighPass'],\n",
    "    use_cgof=True,\n",
    ")\n",
    "signal_filter = optical_flow.preprocess_signal(\n",
    "    raw_signal,\n",
    "    params.fps,\n",
    "    lowpass=hyperparameters['Filter_LowPass'],\n",
    "    highpass=hyperparameters['Filter_HighPass'],\n",
    "    use_cgof=True,\n",
    "    use_filter=True,\n",
    ")\n",
    "signal_normalization = optical_flow.preprocess_signal(\n",
    "    raw_signal,\n",
    "    params.fps,\n",
    "    lowpass=hyperparameters['Filter_LowPass'],\n",
    "    highpass=hyperparameters['Filter_HighPass'],\n",
    "    use_cgof=True,\n",
    "    use_filter=True,\n",
    "    use_normalization=True,\n",
    ")\n",
    "\n",
    "processed_signal = signal_normalization"
   ],
   "id": "7f7b5a3048da95a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "axs[0].plot(preprocessed_unprocessed)\n",
    "axs[0].set_title('Preprocessed (Unprocessed)')\n",
    "\n",
    "axs[1].plot(signal_cgof)\n",
    "axs[1].set_title('Preprocessed (CGOF)')\n",
    "\n",
    "axs[2].plot(signal_filter)\n",
    "axs[2].set_title('Preprocessed (Filter)')\n",
    "\n",
    "plt.show()"
   ],
   "id": "c0df1e526af5308b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy import signal\n",
    "\n",
    "gt_signal, gt_fps = dataset.get_ground_truth_rr_signal(subject, scenario)\n",
    "\n",
    "# Normalize the ground truth signal between 0.5 and -0.5\n",
    "gt_signal = (gt_signal - np.min(gt_signal)) / (np.max(gt_signal) - np.min(gt_signal)) - 0.5"
   ],
   "id": "d1ffdc8ee4031b85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the processed_signal and the gt_signal in the same plot without subplots\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Processed Signal vs Ground Truth Signal')\n",
    "\n",
    "plt.plot(processed_signal, label='Processed Signal')\n",
    "\n",
    "# Downsample the ground truth signal to the same FPS\n",
    "gt_signal_down = signal.resample(gt_signal, len(processed_signal))\n",
    "plt.plot(gt_signal_down, label='Ground Truth Signal')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "fd12a9046a2dc331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "get_ground_truth_rr = dataset.get_ground_truth_rr(subject, scenario)\n",
    "get_ground_truth_rr, get_ground_truth_rr * 60"
   ],
   "id": "9ab2751948c6f9a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the frequencies using the different methods for the ground truth signal\n",
    "frequency = optical_flow.FrequencyExtraction(gt_signal, gt_fps)\n",
    "\n",
    "gt_frequency = {\n",
    "    'FFT': frequency.fft(),\n",
    "    'PC': frequency.peak_counting(),\n",
    "    'CP': frequency.crossing_point(),\n",
    "    'NFCP': frequency.negative_feedback_crossover_point_method()\n",
    "}\n",
    "gt_frequency"
   ],
   "id": "ec52bcb41ebf0536",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for fpn in [None, 5]:\n",
    "    for use_roi in [False, True]:\n",
    "        if use_roi:\n",
    "            roi_mask = subject_roi_mask\n",
    "        else:\n",
    "            roi_mask = None\n",
    "\n",
    "        raw_signal = optical_flow.extract_raw_signal(\n",
    "            subject_frames,\n",
    "            fpn=fpn,\n",
    "            quality_level=0.3,\n",
    "            quality_level_rv=0.05,\n",
    "            roi_mask=roi_mask,\n",
    "        )\n",
    "\n",
    "        breathing_signal = optical_flow.preprocess_signal(\n",
    "            raw_signal,\n",
    "            params.fps,\n",
    "            use_cgof=True,\n",
    "            use_filter=True,\n",
    "            use_normalization=True,\n",
    "        )\n",
    "\n",
    "        frequency = optical_flow.FrequencyExtraction(breathing_signal, params.fps)\n",
    "\n",
    "        predictions = {\n",
    "            'FFT': frequency.fft(),\n",
    "            'PC': frequency.peak_counting(),\n",
    "            'CP': frequency.crossing_point(),\n",
    "            'NFCP': frequency.negative_feedback_crossover_point_method(),\n",
    "        }\n",
    "\n",
    "        for method, value in predictions.items():\n",
    "            evaluation_results.append({\n",
    "                'fpn': fpn if fpn is not None else 'None',\n",
    "                'use_roi': use_roi,\n",
    "                'method': method,\n",
    "                'value': value,\n",
    "                'error': abs(value - gt_frequency[method]),\n",
    "            })"
   ],
   "id": "175368ef91733e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation = pd.DataFrame(evaluation_results)\n",
    "evaluation"
   ],
   "id": "ce74cf8b6ec65d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(15, 10))\n",
    "\n",
    "# Add more space between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "inx = 0\n",
    "for method in gt_frequency.keys():\n",
    "    axs[inx].set_title(f'{method} Method')\n",
    "\n",
    "    # Plot the values for each method\n",
    "    data = evaluation[evaluation['method'] == method]\n",
    "\n",
    "    title = 'fpn=' + data['fpn'].astype(str) + ' / roi=' + data['use_roi'].astype(str)\n",
    "    axs[inx].bar(title, data['error'])\n",
    "\n",
    "    inx += 1"
   ],
   "id": "accad4213dd2bd62",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
